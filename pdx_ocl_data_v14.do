* title: civiclife-profiles22-23-dataset
* purpose: generate a tract level dataset of requested indicators, and then recast to n'hoods
*	using factors generated by Knot inc.
* author: sharygin@pdx.edu
* version: 
*	v14 updating to include districts; changing to gross rent (was contract). first version with 2010 data. 
*		fixed missing REL/RSE (from incorrect formula for SE(P) when value under sqrt is negative). fixing labels.
*	v13 adding 2010 data as well -- facilitates Gilbert's webpage layout. Moved educ vars weight to totpop instead of hhpop
*	v12 fixed bug in languages -- rowranks doesn't work as expected.
*	v11 adding data for coalitions to profile (based on blocks in coalition). updated coalition names.
*		child poverty. adding some manual overrides for block->n'hoods (look at Arlington Heights vs Goose Hollow).
*		converting back to proportional assingment of data, based on sfbo dataset.
*	v10 adding code to sort nhood languages by N speakers and report in order. adding GER and OASI to lang list.
*	v09 swap to using block published internal points (as in Census Reporter), substitute PRC 2010
*		published data instead of recalculating. drop Knot results and use block centroids.
*		Knot factors seem to produce incorrect populations, e.g. Parkrose Heights should be 6205 but is 6050.
*		also dropping the tr10->bk10->bk20 step in favor of going from tr10->bk10->nhood directly.
*		also adding citywide data to profile. fixed calculation bug resulting from taking rawsums+means in one collapse step.
*	v08 swap to using tracts instead of blocks; always use censusapi instead of getcensus; 
*		fix RSE calculations, add "REL" which is reliability (min(100,max(0,100*(1-RSE))))
*		viz. https://acsdatacommunity.prb.org/discussion-forum/f/forum/3/calculating-moes-from-derived-acs-estimates*
*	v07 completed updates started in v06; testing version
*	v06	adding calculation of derived percent/shares and more consistent naming
*		06c: fixed error when API returns error code eg -66666666 should be missing.
*	v05 adding canopy analysis results from randy morris + adding areal statistics to 2010+2020 shps
*	v04 modified deatils and layout; statisics by block not geosumlev; added 2010 DEC data.
*	v03 adding age detail from 2020-DHC; returning to avg of medians when needed.
*	v02 working to point of export to Excel; using agg values/means, and counts.
*	v01 first WIP
* steps
* 1. calculate tr10/tr20->bk20 factors
*	tr20 -> bk20 using geoid
*	tr10 -> bk10 using geoid 
* 2. calculate bk10/bk20->nhood factors
*	bk20 -> nhood from intptlat, intptlon
*	bk10 -> nhood from intptlat, intptlon, but override to use published data for bk10 from prc 2010 profiles.
* 3. retrieve data
* 4. project data to blocks
* 5. aggregate blocks to nhoods
*	explode duplicated zones into copies
* 	drop unclaimed blocks
*	summarize and export to excel.

// setup
foreach p in "censusapi" "shp2dta" "geoinpoly" "rowranks" "isvar" {
	cap which `p'
	if _rc ssc install `p'
}
global path "I:\Research\Home\s\sharygin\_PORTLAND_CIVICLIFE_profiles22-23"
global knot "I:\Research\Shares\population_research\_DATA\KNOT_BK20\Knot_Results_BxN_dec20.csv"
global pl94 "I:\Research\Shares\population_research\_DATA\USCB_DEC\2020_PL94"
global e0 "I:\Research\Shares\population_research\_DATA\NCHS_USALEEP\OR_A.CSV"
global voters "I:\Research\Shares\population_research\_DATA\L2_TURNOUT\OR_l2_turnout_stats_block20.csv"
global sovi "I:\Research\Shares\population_research\_DATA\METRO_SVT\Social_Vulnerability_Tools_2023_Level_1_Social_Vulnerability_Index.csv"
global food "I:\Research\Shares\population_research\_DATA\FEEDAM_FOODINSECURITY\fam_mmg_OR_tracts.dta"
global canopy "I:\Research\Home\s\sharygin\_PORTLAND_CIVICLIFE_profiles22-23\Data\Canopy Analysis\Canopy_Blocks20_table.xls"
global dofactor=0 // re-process geographic allocation factors?
global doblock=0 // re-process data for blocks?
global dotract=0 // re-process data for tracts/city?
global downscale=0 // re-downscale tracts to blocks?
global summarize=0 // re-assemble blocks to n'hoods and export results?
global export=1 // clean, label, and export data?
cd $path

// load census api key
insheet using ckey.txt, clear nonames
global censuskey=v1 in 1

/****************************
* calculate land area		*
****************************/

// calc land area per n'hood
// 2020--nhood
	import delimited using "Boundaries/Overlapping/Neighborhood_Overlap_Area.csv", clear // 2020 nhood area sqmi, whole.
	keep name areasqmi 
	ren areasqmi v1N_sqmi_20
	ren name nname
	drop if strpos(nname,"UNCLAIMED")>0
	replace nname="LLOYD DISTRICT" if nname=="LLOYD"
	save "pdx_ocl_data_nharea.dta", replace
// 2020--coalit
	import delimited using "Boundaries/Intersected/Neighborhood_Intersect_Area.csv", clear // 2020 nhood area sqmi, parts.
	keep coalit areasqmi
	drop if strpos(coalit,"UNCLAIMED")>0
	gen count=strpos(coalit,"/")>0 
	replace count=count+1
	split coalit, p("/")
	expand count, gen(flag)
	replace coalit=coalit1 if flag==0
	replace coalit=coalit2 if flag==1
	drop count coalit1 coalit2 flag
	collapse (sum) v1N_sqmi_20=areasqmi, by(coalit)
	ren coalit nname 
	merge 1:1 nname using "pdx_ocl_data_nharea.dta", assert(1 2) nogen update
	save "pdx_ocl_data_nharea.dta", replace
// 2010--nhood
	import delimited using "Boundaries/pdx_neighborhoods_2011/neighborhoods_intersect_area", clear // 2010 nhood area sqmi, parts
	keep name areasqmi
	ren name nname
	replace nname="OLD TOWN" if nname=="OLD TOWN/CHINATOWN"
	gen count=strpos(nname,"/")>0 
	replace count=count+1
	split nname, p("/")
	expand count, gen(flag)
	replace nname=nname1 if flag==0
	replace nname=nname2 if flag==1
	drop count nname1 nname2 flag
	collapse (sum) v1N_sqmi_10=areasqmi, by(nname)
	replace nname="BROOKLYN" if nname=="BROOKLYN ACTION CORPS" 
	replace nname="ARGAY TERRACE" if nname=="ARGAY"
	replace nname="SELLWOOD-MORELAND" if nname=="SELLWOOD-MORELAND IMPROVEMENT LEAGUE"
	replace nname="PORTLAND DOWNTOWN" if nname=="DOWNTOWN"
	replace nname="PEARL DISTRICT" if nname=="PEARL"
	drop if inlist(nname,"MAYWOOD PARK","NORTHWEST INDUSTRIAL") // NW INDUSTRIAL = MC UNCLAIMED #14
	drop if strpos(nname,"UNCLAIMED")>0
	merge 1:1 nname using "pdx_ocl_data_nharea.dta", assert(2 3) nogen update
	save "pdx_ocl_data_nharea.dta", replace 
// 2010--coalit
	import delimited using "Boundaries/pdx_neighborhoods_2011/neighborhoods_intersect_area", clear // 2010 nhood area sqmi, parts
	drop if inlist(coalit,"none","NONE","unclaimed","UNCLAIMED")
	drop if trim(coalit)==""
	keep coalit areasqmi 
	gen count=strpos(coalit,"/")>0 
	replace count=count+1
	split coalit, p("/")
	expand count, gen(flag)
	replace coalit=coalit1 if flag==0
	replace coalit=coalit2 if flag==1
	drop count coalit1 coalit2 flag
	collapse (sum) v1N_sqmi_10=areasqmi, by(coalit)
	replace coalit="EPCO" if coalit=="EPNO" // update names to those used in 2020 
	replace coalit="SWCS" if coalit=="SWNI"
	ren coalit nname 
	merge 1:1 nname using "pdx_ocl_data_nharea.dta", assert(2 3) nogen update
// 2010+2020--city
	local n=_N+1
	set obs `n'
	replace nname="CITY OF PORTLAND" in `n'
	replace v1N_sqmi_10=4041168718.45057/25899880 in `n'
	replace v1N_sqmi_20=4044530283.57422/25899880 in `n'
	format v1N_sqmi_10 v1N_sqmi_20 %6.2f
// 2020--districts
	local n=_N+1
	set obs `n'
	replace nname="District 1" in `n'	
	replace v1N_sqmi_10=36.944092 in `n'
	replace v1N_sqmi_20=36.944092 in `n'
	local n=_N+1
	set obs `n'
	replace nname="District 2" in `n'	
	replace v1N_sqmi_10=41.623327 in `n'
	replace v1N_sqmi_20=41.623327 in `n'
	local n=_N+1
	set obs `n'
	replace nname="District 3" in `n'	
	replace v1N_sqmi_10=21.049381 in `n'
	replace v1N_sqmi_20=21.049381 in `n'
	local n=_N+1
	set obs `n'
	replace nname="District 4" in `n'	
	replace v1N_sqmi_10=45.375858 in `n'
	replace v1N_sqmi_20=45.375858 in `n'
	save "pdx_ocl_data_nharea.dta", replace 
	
	
/****************************
* geo allocation factors	*
****************************/

// check before redoing geographic factors
if $dofactor==1 {

// fraction of bg/tract POP/HU in constitutent blocks (from DEC20)
	use if SUMLEV=="750" using $pl94/pl94.dta, clear
	rename *, lower
	gen hu20=h0010001
	gen hh20=h0010002
	gen hhpop20=p0010001-p0050001
	gen gqpop20=p0050001
	gen pop20=p0010001
	gen gidtr20="41"+county+tract
	gen gidbg20="41"+county+tract+blkgrp
	gen gidbk20=geocode
	foreach g in "bg" "tr" { 
		egen `g'20_hu=sum(hu20), by(gid`g'20)
		egen `g'20_hh=sum(hh20), by(gid`g'20)
		egen `g'20_hhpop=sum(hhpop20), by(gid`g'20)
		egen `g'20_gqpop=sum(gqpop20), by(gid`g'20)
		egen `g'20_pop=sum(pop20), by(gid`g'20)
		foreach h in "hu" "hh" "pop" "hhpop" "gqpop" {
			gen bk20_shr_`g'20_`h'=`h'20/`g'20_`h' 
			replace bk20_shr_`g'20_`h'=0 if bk20_shr_`g'20_`h'==.
		}
	}
	keep gidtr20 gidbg20 gidbk20 bk20*
	subsave gidbk20 gidtr20 bk20_shr_tr20* using "pdx_ocl_tr20_to_bk20_factors.dta", replace
	*subsave gidbk20 gidbg20 bk20_shr_bg20* using "pdx_ocl_bg20_to_bk20_factors.dta", replace
//
// fraction of 2010 tract in each 2010 block (from DEC10)
	censusapi, url("https://api.census.gov/data/2010/dec/sf1?get=P001001,H003003,H011001,GEO_ID&for=block:*&in=state:41&in=county:005,051,067&in=tract:*&key=$censuskey")
	gen gidtr10=substr(geo_id,10,11)
	gen gidbk10=substr(geo_id,10,.)
	egen trsum=sum(p001001), by(gidtr10)
	gen bk10_shr_tr10_pop=p001001/trsum
	egen hhsum=sum(h003003), by(gidtr10)
	gen bk10_shr_tr10_hh=h003003/hhsum
	egen hhpopsum=sum(h011001), by(gidtr10)
	gen bk10_shr_tr10_hhpop=h011001/hhpopsum
	keep gidbk10 gidtr10 bk10_shr_tr10_*
	save "pdx_ocl_tr10_to_bk10_factors.dta", replace
//
// assignment of 2010 blocks->2010 n'hoods (by fraction of BF polygons in each nhood part)
	import delim using data/tl20bk10_sfbo_polygons.csv, clear // polys per block (contains blocks nearby to nhoods)
	keep geoid count sum_sq_ft 
	ren geoid gidbk10
	ren count sfbo_bkpoly
	ren sum_sq_ft sfbo_bksqft
	save "pdx_ocl_bk10_to_nhood11_sfbo.dta", replace
	import delim using data/tl20bk10_nhood11_split_sfbo_polygons.csv, clear // polys per block part (if no polys in the part then missing)
	keep geoid name coalit count sum_sq_ft
	ren geoid gidbk10
	ren name nname
	ren sum_sq_ft sfbo_bksqft_nhood
	ren count sfbo_bkpoly_nhood
	merge m:1 gidbk10 using "pdx_ocl_bk10_to_nhood11_sfbo.dta", assert(2 3) keepus(sfbo_bkpoly sfbo_bksqft) 
	tostring gidbk10, replace format(%15.0f)
	gen nhood11_shr_bk10_sfbo=sfbo_bksqft_nhood/sfbo_bksqft
	* gen nhood11_shr_bk10_sfbo=sfbo_bkpoly_nhood/sfbo_bkpoly
	list if inlist(gidbk10,"410050222062002","410050222062000","410050222061000"), clean noobs
	list if inlist(gidbk10,"410050201001068","410050201001067"), clean noobs // partly in arnold creek, mostly none.
	list if inlist(gidbk10,"410510046012002","410510043001102"), clean noobs // linnton, goose hollow
	keep gidbk10 nname coalit nhood11_shr_bk10_sfbo 
	ren nhood11_shr_bk10_sfbo prop_r10_sqft 
	replace prop_r10_sqft=round(prop_r10_sqft,.01)
	list if inlist(gidbk10,"410510046012002","410510043001102")
	count if nname!="" & (prop_r10_sqft==.|prop_r10_sqft==0) // intersecting blocks w/no populated parts in n'hood.
	replace prop_r10_sqft=0 if prop_r10_sqft==. & nname!=""
	label var prop_r10_sqft "Share of block10 pop in block*nood fragment (from sfbo sqft)"
	save "pdx_ocl_bk10_to_nhood11_sfbo.dta", replace 
//
// assignment of 2010 blocks->2020 n'hoods (by centroids).
** 2010 block data for 2020 n'hoods includes ONLY food (from tr10) e0 (from tr10) 
** since these are not count data, they can be assigned wholesale to a single associated 2020 block.
	import delim using data/tl20bk10_points_nhood20.csv, clear // agp: tl20bk10 points spatial joined to nhood20
	ren geoid gidbk10
	ren name nname
	keep gidbk10 nname coalit
	tostring gidbk10, replace format(%15.0f)
	save "pdx_ocl_bk10_to_nhood20_points.dta", replace
//
// assignment of 2010 blocks->2020 districts (by internal points)
	** in gis, import 2010 blocks xy, spatial join to district map, respectively, and export csv.
	** this way doesn't use shp2dta and geoinpoly, but those don't support the Oregon Lambert projection.
	import delim using data/tl20bk10_points_districts.csv, clear 
	drop oid_
	ren geoid gidbk10
	tostring gidbk10, format(%15.0f) replace
	tostring district, replace
	replace district="District "+district
	ren district nname
	save "pdx_ocl_bk10_to_district.dta", replace
//
// assignment of 2020 blocks->2020 districts (by internal points)
	** in gis, import 2020 blocks xy, spatial join to district map, respectively, and export csv.
	** this way doesn't use shp2dta and geoinpoly, but those don't support the Oregon Lambert projection.
	import delim using data/tl20bk20_points_districts.csv, clear 
	drop oid_
	tostring gidbk20, format(%15.0f) replace
	tostring district, replace
	replace district="District "+district
	ren district nname
	save "pdx_ocl_bk20_to_district.dta", replace
//
// assignment of 2020 n'hoods to 2020 coalits (from admin data)
	import delim using boundaries/intersected/Neighborhood_Intersect_Area.csv, clear
	keep name coalit
	ren name nname
	duplicates drop
	save "pdx_ocl_nhood20_to_coalit.dta", replace
//
// assignment of 2020 blocks->2020 n'hoods (by fraction of BF polygons in each nhood part)
	import delim using data/tl20bk20_sfbo_polygons.csv, clear // polys per block (contains blocks nearby to nhoods)
	keep geoid count sum_sq_ft 
	ren geoid gidbk20
	ren count sfbo_bkpoly
	ren sum_sq_ft sfbo_bksqft
	save "pdx_ocl_bk20_to_nhood20_sfbo.dta", replace
	import delim using data/tl20bk20_nhood20_split_sfbo_polygons.csv, clear // polys per block part (if no polys in the part then missing)
	keep geoid name coalit count sum_sq_ft
	ren geoid gidbk20
	ren name nname
	ren sum_sq_ft sfbo_bksqft_nhood
	ren count sfbo_bkpoly_nhood
	merge m:1 gidbk20 using "pdx_ocl_bk20_to_nhood20_sfbo.dta", assert(2 3) keepus(sfbo_bkpoly sfbo_bksqft) 
	tostring gidbk20, replace format(%15.0f)
	*gen nhood20_shr_bk20_sfbo=sfbo_bkpoly_nhood/sfbo_bkpoly
	gen nhood20_shr_bk20_sfbo=sfbo_bksqft_nhood/sfbo_bksqft
	list if inlist(gidbk20,"410050222062002","410050222062000","410050222061000"), clean noobs
	list if inlist(gidbk20,"410050201001068","410050201001067"), clean noobs // partly in arnold creek, mostly none.
	list if inlist(gidbk20,"410510046012002","410510043001102") // linnton, goose hollow
	keep gidbk20 nname coalit nhood20_shr_bk20_sfbo 
	ren nhood20_shr_bk20_sfbo prop_r20_sqft 
	replace prop_r20_sqft=round(prop_r20_sqft,.01)
	list if inlist(gidbk20,"410510046012002","410510043001102")
	count if nname!="" & (prop_r20_sqft==.|prop_r20_sqft==0) // intersecting blocks w/no populated parts in n'hood.
	replace prop_r20_sqft=0 if prop_r20_sqft==. & nname!=""
	label var prop_r20_sqft "Share of block10 pop in block*nood fragment (from sfbo sqft)"
	save "pdx_ocl_bk20_to_nhood20_sfbo.dta", replace 
//
// blocks within portland -- 2020
	cap confirm file Block20Assign_ST41_OR.zip
	if _rc {
		!curl https://www2.census.gov/geo/docs/maps-data/data/baf2020/BlockAssign_ST41_OR.zip --output Block20Assign_ST41_OR.zip
	}
	!unzip -p Block20Assign_ST41_OR.zip BlockAssign_ST41_OR_INCPLACE_CDP.txt > BlockAssign_ST41_OR_INCPLACE_CDP.txt
	import delim using BlockAssign_ST41_OR_INCPLACE_CDP.txt, clear delim("|") stringc(_all) // 2020 blocks to CDP/INCPLACE FIPS codes
	keep if placefp=="59000"
	ren blockid gidbk20
	save "pdx_bk20_in_pdx.dta", replace
	rm BlockAssign_ST41_OR_INCPLACE_CDP.txt
//
// blocks within portland -- 2010
	cap confirm file Block10Assign_ST41_OR.zip
	if _rc {
		!curl https://www2.census.gov/geo/docs/maps-data/data/baf/BlockAssign_ST41_OR.zip --output Block10Assign_ST41_OR.zip
	}
	!unzip -p Block10Assign_ST41_OR.zip BlockAssign_ST41_OR_INCPLACE_CDP.txt > BlockAssign_ST41_OR_INCPLACE_CDP.txt
	import delim using BlockAssign_ST41_OR_INCPLACE_CDP.txt, clear delim(",") stringc(_all) // 2020 blocks to CDP/INCPLACE FIPS codes
	keep if placefp=="59000"
	ren blockid gidbk10
	save "pdx_bk10_in_pdx.dta", replace
	rm BlockAssign_ST41_OR_INCPLACE_CDP.txt

// end check if redoing geo factors
}

/****************************
* document data needed		*
****************************/

// data for profiles
** Census APIs: https://www.census.gov/data/developers/data-sets.html
** getcensus works for ACS, censusapi for all others.
** API: (1) appears it cannot get blocks within MSA, and (2) appears it cannot request multiple counties at once.
** censusapi, url("https://api.census.gov/data/2020/dec/pl?get=GEO_ID,P1_001N,P3_001N&for=block:*&in=state:41&in=county:051&key=$censuskey")
** censusapi, url(https://api.census.gov/data/2020/dec/responserate?get=NAME,GEO_ID,DRRALL,CRRINT,RESP_DATE,CRRALL,DRRINT&for=tract:*&in=state:01&in=county:*&key=$censuskey")
** USDA API: https://www.ers.usda.gov/developer/geospatial-apis/
** 
/*	neighborhoods:
	BLOCKS						2010	2020  					ACS/misc					src		spatial
	1.1 total population 	#	pl94	pl94			    	3.1 tothh				#	pl94	bk
	1.2 <5					#	sf1		dhc	P12	            	3.2 rentburd			% 	B25070	bg/rhu	
	1.3 Age 5-9				#	sf1		dhc	P12	            	3.3 severely rent burd	%	B25070	bg/rhu	
	1.4 Age 10-14			#			dhc	P12		        	3.4	severely crowd		%	B25014	bg/hh	
	1.5 Age 15-19			#			dhc	P12		        	3.5	with 1+ children	%	B11005	bg/hh	
	1.6 Age 20-24			#			dhc	P12		        	3.6 pph 				#	pl94	bk
	1.7 Age 25-29			#			dhc	P12		        	3.7 vacancy rate		%	pl94	bk
	1.8 Age 30-34			#			dhc	P12             	3.8 homeownership		%	B25003	bg/hh	
	1.9 Age 35-39			#			dhc	P12             	3.9 median own homeval	$	B25082	bg/whu 
	1.A Age 40-44			#			dhc	P12             	3.A median contr. rent	$	B25064	bg/rhu	
	1.B Age 45-49			#			dhc	P12             	4.1 reg.voters			%	L2		bk20/18+
	1.C Age 50-54			#			dhc	P12             	4.2 broadbnd 			%	B28011	bg/hh
	1.D Age 55-59			#			dhc	P12             	4.3	census srr			%	api		tr/hh
	1.E Age 60-64			#			dhc	P12             	4.4 moved to PDX<12mo	%	B07204	tr/1+
	1.F Age 65-69			#			dhc	P12             	5.1 shr w/no ged		%	B15003	bg/25+
	1.G Age 70-74			#			dhc	P12             	5.2 shr w/ba+			%	B15003	bg/25+
	1.H Age 75-79			#			dhc	P12	            	5.3 shr chd in ps		%	B14003	tr/3+IS
	1.I Age 80+  			#			dhc	P12             	6.1 food insecur		%	USDA	tr10/.
	1.J Age <18				#			dhc p12     			6.2	disability			%	B18108	tr/civ.ni.
	1.K Age 18-64			#	        dhc p12               	6.3	Metro SVI			#	RLIS	tr/.
	1.L Age 65+				#	        dhc p12                	6.4	e0					#	USALEEP	tr10/.
	1.M Median Age			# 			dhc	P13_001N           	6.5 canopy				%	RLIS	bk
	1.N AREA				#	shp                 			7.1 pov					%	C17002	bg/povu
	1.O DENSITY				#	.	                          	7.2 median hhinc		$	B19001	bg/hh
	2.1 total races tallied	#	pl94	pl94                	7.3 below $75k			%	B19001	bg/hh
	2.2 aian aoic			#	pl94	pl94                	8.1 lang:LEP			#	C16001	tr/5+
	2.3 asian aoic			#	pl94	pl94                	8.2 lep:spa				#	C16001	tr <<-- list these by rank
	2.4 black aoic			#	pl94	pl94                	8.3	lep:fre				#	C16001 	tr
	2.5 nhpi aoic			#	pl94	pl94                	8.4 lep:slav			#	C16001  tr
	2.6 sor aoic			#	pl94	pl94                	8.5 lep:othi			#	C16001  tr
	2.7 white aoic			#	pl94	pl94                	8.6 lep:kor				#	C16001  tr
	2.8 hispan 				#	pl94	pl94                	8.7 lep:chn				#	C16001  tr
	2.9 wanh				#	pl94	pl94                	8.8 lep:vie				#	C16001  tr
																8.9 lep:tgl				#	C16001  tr
                                                            	8.A lep:ara				#	C16001  tr
                                                            	8.B lep:othr			#	C16001  tr							
*/
*	+ canopy https://gis.oregonmetro.gov/rlis-metadata/#/details/3726
*	+ vacant https://gis.oregonmetro.gov/rlis-metadata/#/details/2833
*
*	citywide extra (from PUMS, controlled to city)
*	y.* languages
*	z.* langauges*poverty
*	x.1 anc:eur			
*   x.2 anc:mena		
*   x.3 anc:carib/	
*   x.4 anc:w.c.as
*   x.5 anc:e.asia
*   x.6 anc:africa
*
*	templates (excel):
*	-- new horizontal layout and coloring schemes
*	-- new ranker tables of neighborhoods ranked (all n'hoods, each variable)
*
*	interactive tool:
*	-- new 2-neighborhood comparator (2 n'hoods, all variables)
*	-- new filter list of neighborhoods by interval of values of a characteristics

/****************************
* block+city data			*
****************************/

// begin check before redoing block-data
if $doblock==1 {

// dummy files
	touch pdx_ocl_data_bk10.dta, replace // first save, overwrite.
	touch pdx_ocl_data_bk20.dta, replace
//
// table 1, part 1. age (2010 and 2020)
foreach f in "block:*&in=county:005,051,067&in=state:41" "place:59000&in=state:41" {
	// 2010
	censusapi, url("https://api.census.gov/data/2010/dec/sf1?get=group(P12)&for=`f'&key=$censuskey") // 11mb
	gen v11_total_10=p012001
	gen v12_age0004_10=p012003+p012027
	gen v13_age0509_10=p012004+p012028
	gen v14_age1014_10=p012005+p012029
	gen v15_age1519_10=p012006+p012007+p012030+p012031 
	gen v16_age2024_10=p012008+p012009+p012010+p012032+p012033+p012034
	gen v17_age2529_10=p012011+p012035
	gen v18_age3034_10=p012012+p012036
	gen v19_age3539_10=p012013+p012037
	gen v1A_age4044_10=p012014+p012038
	gen v1B_age4549_10=p012015+p012039
	gen v1C_age5054_10=p012016+p012040
	gen v1D_age5559_10=p012017+p012041
	gen v1E_age6064_10=p012018+p012019+p012042+p012043 
	gen v1F_age6569_10=p012020+p012021+p012044+p012045 
	gen v1G_age7074_10=p012022+p012046
	gen v1H_age7579_10=p012023+p012047
	gen v1I_age80pl_10=p012024+p012025+p012048+p012049
	gen v1J_agelt18_10=v12_age0004+v13_age0509+v14_age1014+p012006+p012030
	gen v1K_age1864_10=p012007+p012031+v16_age2024+v17_age2529+v18_age3034+v19_age3539+v1A_age4044+v1B_age4549+v1C_age5054+v1D_age5559+v1E_age6064
	gen v1L_age65pl_10=v1F_age6569+v1G_age7074+v1H_age7579+v1I_age80pl
	gen gidbk10=substr(geo_id,10,.)
	keep gidbk10 v1*
	cap merge 1:1 gidbk10 using pdx_ocl_data_bk10.dta, nogen update // first time, cap
	save pdx_ocl_data_bk10.dta, replace 
	// 2020
	censusapi, url("https://api.census.gov/data/2020/dec/dhc?get=group(P12)&for=`f'&key=$censuskey") // 16mb
	gen v11_total_20=p12_001n
	gen v12_age0004_20=p12_003n+p12_027n
	gen v13_age0509_20=p12_004n+p12_028n
	gen v14_age1014_20=p12_005n+p12_029n
	gen v15_age1519_20=p12_006n+p12_007n+p12_030n+p12_031n 
	gen v16_age2024_20=p12_008n+p12_009n+p12_010n+p12_032n+p12_033n+p12_034n
	gen v17_age2529_20=p12_011n+p12_035n
	gen v18_age3034_20=p12_012n+p12_036n
	gen v19_age3539_20=p12_013n+p12_037n
	gen v1A_age4044_20=p12_014n+p12_038n
	gen v1B_age4549_20=p12_015n+p12_039n
	gen v1C_age5054_20=p12_016n+p12_040n
	gen v1D_age5559_20=p12_017n+p12_041n
	gen v1E_age6064_20=p12_018n+p12_019n+p12_042n+p12_043n 
	gen v1F_age6569_20=p12_020n+p12_021n+p12_044n+p12_045n 
	gen v1G_age7074_20=p12_022n+p12_046n
	gen v1H_age7579_20=p12_023n+p12_047n
	gen v1I_age80pl_20=p12_024n+p12_025n+p12_048n+p12_049n
	gen v1J_agelt18_20=v12_age0004+v13_age0509+v14_age1014+p12_006n+p12_030n
	gen v1K_age1864_20=p12_007n+p12_031n+v16_age2024+v17_age2529+v18_age3034+v19_age3539+v1A_age4044+v1B_age4549+v1C_age5054+v1D_age5559+v1E_age6064
	gen v1L_age65pl_20=v1F_age6569+v1G_age7074+v1H_age7579+v1I_age80pl
	gen gidbk20=substr(geo_id,10,.)
	keep gidbk20 v1* 
	cap merge 1:1 gidbk20 using pdx_ocl_data_bk20.dta, nogen update // first time, cap
	save pdx_ocl_data_bk20.dta, replace 
}
//
// table 1, part 2. median age (2010 and 2020)
foreach f in "block:*&in=county:005,051,067&in=state:41" "place:59000&in=state:41" {
	//2010
	censusapi, url("https://api.census.gov/data/2010/dec/sf1?get=GEO_ID,P013001&for=`f'&key=$censuskey") // median age
	gen gidbk10=substr(geo_id,10,.)
	gen v9_medage_10=p013001 if p013001>0
	keep gidbk10 v9_medage_10
	merge 1:1 gidbk10 using pdx_ocl_data_bk10.dta, nogen update
	save pdx_ocl_data_bk10.dta, replace 
	//2020
	censusapi, url("https://api.census.gov/data/2020/dec/dhc?get=GEO_ID,P13_001N&for=`f'&key=$censuskey") // median age
	gen gidbk20=substr(geo_id,10,.)
	gen v9_medage_20=p13_001n if p13_001n>0
	keep gidbk20 v9_medage_20
	merge 1:1 gidbk20 using pdx_ocl_data_bk20.dta, nogen update
	save pdx_ocl_data_bk20.dta, replace 
}
//
// table 2. race/eth (2010 and 2020)
foreach s in "750" "160" {
	//2020
	use $pl94/pl94_varnames.dta, clear
	levelsof var1 if strpos(var2,"indian")>0 & strpos(var1,"p001")==1, clean local(aian)
	levelsof var1 if strpos(var2,"asia")>0 & strpos(var1,"p001")==1,  clean local(asian)
	levelsof var1 if strpos(var2,"black")>0 & strpos(var1,"p001")==1,  clean local(black)
	levelsof var1 if strpos(var2,"hawai")>0 & strpos(var1,"p001")==1,  clean local(nhpi)
	levelsof var1 if strpos(var2,"other")>0 & strpos(var1,"p001")==1,  clean local(other)
	levelsof var1 if strpos(var2,"white")>0 & strpos(var1,"p001")==1,  clean local(white)
	use if SUMLEV=="`s'" using $pl94/pl94.dta, clear // OR blocks only
	if "`s'"=="750" keep if inlist(COUNTY,"005","051","067")
	if "`s'"=="160" keep if PLACE=="59000"
	ren *, lower
	gen  v21_trt_20=p0010002+p0010010*2+p0010026*3+p0010047*4+p0010063*5+p0010070*6
	egen v22_aian_20=rowtotal(`aian')
	egen v23_asian_20=rowtotal(`asian')
	egen v24_black_20=rowtotal(`black')
	egen v25_nhpi_20=rowtotal(`nhpi')
	egen v26_sor_20=rowtotal(`other')
	egen v27_white_20=rowtotal(`white')
	gen  v28_hispan_20=p0020002
	gen  v29_wanh_20=p0020005
	ren geocode gidbk20
	keep gidbk20 v2*
	merge 1:1 gidbk20 using pdx_ocl_data_bk20.dta, nogen update
	save pdx_ocl_data_bk20.dta, replace
	//2010
	use $pl94/pl94_varnames.dta, clear
	levelsof var1 if strpos(var2,"indian")>0 & strpos(var1,"p001")==1, clean local(aian)
	levelsof var1 if strpos(var2,"asia")>0 & strpos(var1,"p001")==1,  clean local(asian)
	levelsof var1 if strpos(var2,"black")>0 & strpos(var1,"p001")==1,  clean local(black)
	levelsof var1 if strpos(var2,"hawai")>0 & strpos(var1,"p001")==1,  clean local(nhpi)
	levelsof var1 if strpos(var2,"other")>0 & strpos(var1,"p001")==1,  clean local(other)
	levelsof var1 if strpos(var2,"white")>0 & strpos(var1,"p001")==1,  clean local(white)
	if "`s'"=="750" censusapi, url("https://api.census.gov/data/2010/dec/pl?get=group(P1)&for=block:*&in=county:005,051,067&in=state:41&key=$censuskey") // pl94-2010 ~~ 14mb
	if "`s'"=="160" censusapi, url("https://api.census.gov/data/2010/dec/pl?get=group(P1)&for=place:59000&in=state:41&key=$censuskey") // pl94-2010
	ren *, lower
	gen  v21_trt_10=p001002+p001010*2+p001026*3+p001047*4+p001063*5+p001070*6
	egen v22_aian_10=rowtotal(p001005 p001012 p001016 p001020 p001021 p001022 p001027 p001031 p001032 p001033 p001037 p001038 p001039 p001043 p001044 p001045 p001048 p001049 p001050 p001054 p001055 p001056 p001058 p001059 p001060 p001062 p001064 p001065 p001066 p001068 p001069 p001071)
	egen v23_asian_10=rowtotal(p001006 p001013 p001017 p001020 p001023 p001024 p001028 p001031 p001034 p001035 p001037 p001040 p001041 p001043 p001044 p001046 p001048 p001051 p001052 p001054 p001055 p001057 p001058 p001059 p001061 p001062 p001064 p001065 p001067 p001068 p001069 p001071)
	egen v24_black_10=rowtotal(p001004 p001011 p001016 p001017 p001018 p001019 p001027 p001028 p001029 p001030 p001037 p001038 p001039 p001040 p001041 p001042 p001048 p001049 p001050 p001051 p001052 p001053 p001058 p001059 p001060 p001061 p001064 p001065 p001066 p001067 p001069 p001071)
	egen v25_nhpi_10=rowtotal(p001007 p001014 p001018 p001021 p001023 p001025 p001029 p001032 p001034 p001036 p001038 p001040 p001042 p001043 p001045 p001046 p001049 p001051 p001053 p001054 p001056 p001057 p001058 p001060 p001061 p001062 p001064 p001066 p001067 p001068 p001069 p001071)
	egen v26_sor_10=rowtotal(p001008 p001015 p001019 p001022 p001024 p001025 p001030 p001033 p001035 p001036 p001039 p001041 p001042 p001044 p001045 p001046 p001050 p001052 p001053 p001055 p001056 p001057 p001059 p001060 p001061 p001062 p001065 p001066 p001067 p001068 p001069 p001071)
	egen v27_white_10=rowtotal(p001003 p001011 p001012 p001013 p001014 p001015 p001027 p001028 p001029 p001030 p001031 p001032 p001033 p001034 p001035 p001036 p001048 p001049 p001050 p001051 p001052 p001053 p001054 p001055 p001056 p001057 p001064 p001065 p001066 p001067 p001068 p001071)
	gen gidbk10=substr(geo_id,10,.)
	keep gidbk10 v2*
	merge 1:1 gidbk10 using pdx_ocl_data_bk10.dta, nogen update
	save pdx_ocl_data_bk10.dta, replace
	if "`s'"=="750" censusapi, url("https://api.census.gov/data/2010/dec/pl?get=GEO_ID,P002002,P002005&for=block:*&in=county:005,051,067&in=state:41&key=$censuskey") // pl94-2010
	if "`s'"=="160" censusapi, url("https://api.census.gov/data/2010/dec/pl?get=GEO_ID,P002002,P002005&for=place:59000&in=state:41&key=$censuskey") // pl94-2010
	gen  v28_hispan_10=p002002
	gen  v29_wanh_10=p002005
	gen gidbk10=substr(geo_id,10,.)
	keep gidbk10 v2*
	merge 1:1 gidbk10 using pdx_ocl_data_bk10.dta, nogen update
	save pdx_ocl_data_bk10.dta, replace
}
//
// table 3, part 1. housing (blocks)--2010+2020
foreach s in "750" "160" {
	// 2010
	if "`s'"=="750" censusapi, url("https://api.census.gov/data/2010/dec/sf1?get=GEO_ID,H003001,H003002,H003003,H010001&for=block:*&in=county:005,051,067&in=state:41&key=$censuskey")
	if "`s'"=="160" censusapi, url("https://api.census.gov/data/2010/dec/sf1?get=GEO_ID,H003001,H003002,H003003,H010001&for=place:59000&in=state:41&key=$censuskey")
	gen v31_tothh_10=h003002
	gen v36_hhpop_10=h010001
	gen v37_vacant_10=h003003
	gen v37_tothu_10=h003001
	gen gidbk10=substr(geo_id,10,.)
	keep gidbk10 v3*
	merge 1:1 gidbk10 using pdx_ocl_data_bk10.dta, nogen update
 	order g v3*, alpha
	save pdx_ocl_data_bk10.dta, replace 
	// 2020
	use if SUMLEV=="`s'" using $pl94/pl94.dta, clear // OR blocks only
	if "`s'"=="750" keep if inlist(COUNTY,"005","051","067")
	if "`s'"=="160" keep if PLACE=="59000"
	ren *, lower
	gen v31_tothh_20=h0010002
	gen v36_hhpop_20=(p0010001-p0050001)
	gen v37_vacant_20=h0010001-h0010002
	gen v37_tothu_20=h0010001
	ren geocode gidbk20
	keep gidbk20 v3*
	merge 1:1 gidbk20 using pdx_ocl_data_bk20.dta, nogen update
 	order g v3*, alpha
	save pdx_ocl_data_bk20.dta, replace 
}
//
// table 4, part 1. engagement (blocks)--2020
	import delim using $voters, clear stringc(2) // L2 voters (2020 blocks)
	keep geoid20 g20201103_voted_all g20201103_reg_all g20201103_pct_voted_all
	ren geoid20 gidbk20
	gen v41_turnout=g20201103_voted_all // later divide by age18+ for participation rate.
	gen v41_regvot=g20201103_reg_all 
	keep gidbk20 v41*
	preserve
	keep if inlist(substr(gidbk20,1,5),"41005","41051","41067")
	merge 1:1 gidbk20 using pdx_ocl_data_bk20.dta, nogen
	save pdx_ocl_data_bk20.dta, replace
	restore // city
	merge 1:1 gidbk20 using pdx_bk20_in_pdx.dta, keep(3) nogen
	assert _N>0
	collapse (sum) v41*, by(placefp)
	replace placefp="41"+placefp
	ren placefp gidbk20
	merge 1:1 gidbk20 using pdx_ocl_data_bk20.dta, nogen update
	save pdx_ocl_data_bk20.dta, replace
//
// table 6, part 5: canopy area analysis per bk20
	import excel using "$canopy", firstrow clear
	gen gidbk20=GEOID
	gen v65_canopy_sqkm=SQKm_Canopy
	keep gidbk20 v65_canopy_sqkm
	preserve
	merge 1:1 gidbk20 using pdx_ocl_data_bk20.dta, keep(2 3) nogen
	replace v65_canopy_sqkm=0 if v65_canopy_sqkm==. // no canopy cover measured
	save pdx_ocl_data_bk20.dta, replace
	restore // city
	merge 1:1 gidbk20 using pdx_bk20_in_pdx.dta, keep(3) nogen
	assert _N>0
	collapse (sum) v65_canopy_sqkm, by(placefp)
	replace placefp="41"+placefp
	ren placefp gidbk20
	merge 1:1 gidbk20 using pdx_ocl_data_bk20.dta, nogen update
	save pdx_ocl_data_bk20.dta, replace

// end check if doing census block data
}

/****************************
* tract+city data			*
****************************/

// begin check if redoing tracts
if $dotract==1 {

// init empty datasets
	touch pdx_ocl_data_tr20.dta, replace
	touch pdx_ocl_data_tr10.dta, replace
//
// table 3, part 2. housing (tracts--2010,2020)
forvalues y=2010(10)2020 {
	local z=`y'-2000
	local ayr=`y'+1
foreach f in "tract:*&in=county:005,051,067&in=state:41" "place:59000&in=state:41" {
	censusapi, url("https://api.census.gov/data/`ayr'/acs/acs5?get=group(B25070)&for=`f'&key=$censuskey") // rentburden
	gen gidtr`z'=substr(geo_id,10,.)
	gen v32_rentburd_`z'e=(b25070_007e+b25070_008e+b25070_009e+b25070_010e)
	gen v32_rentburd_`z'd=b25070_001e
	gen v32_rentburd_`z'ese=sqrt((b25070_007m/1.645)^2+(b25070_008m/1.645)^2+(b25070_009m/1.645)^2+(b25070_010m/1.645)^2)
	gen v32_rentburd_`z'dse=b25070_001m/1.645
	gen v33_srntburd_`z'e=b25070_010e
	gen v33_srntburd_`z'd=b25070_001e
	gen v33_srntburd_`z'ese=b25070_010m/1.645
	gen v33_srntburd_`z'dse=b25070_001m/1.645
	keep gidtr`z' v32* v33*
	cap merge 1:1 gidtr`z' using pdx_ocl_data_tr`z'.dta, update nogen // cap on first time
	save pdx_ocl_data_tr`z'.dta, replace // first save 
	censusapi, url("https://api.census.gov/data/`ayr'/acs/acs5?get=group(B25014)&for=`f'&key=$censuskey") // crowding (>1 or >1.5 ppr)
	gen gidtr`z'=substr(geo_id,10,.)
	gen v34_scrowd_`z'e=(b25014_006e+b25014_007e+b25014_012e+b25014_013e)
	gen v34_scrowd_`z'd=b25014_001e
	gen v34_scrowd_`z'ese=sqrt((b25014_006m/1.645)^2+(b25014_007m/1.645)^2+(b25014_012m/1.645)^2+(b25014_013m/1.645)^2)
	gen v34_scrowd_`z'dse=b25014_001m/1.645
	keep gidtr`z' v34*
	merge 1:1 gidtr`z' using pdx_ocl_data_tr`z'.dta, update nogen
	save pdx_ocl_data_tr`z'.dta, replace
	censusapi, url("https://api.census.gov/data/`ayr'/acs/acs5?get=group(B11005)&for=`f'&key=$censuskey") // children
	gen gidtr`z'=substr(geo_id,10,.)
	gen v35_hhchd_`z'e=b11005_002e
	gen v35_hhchd_`z'd=b11005_001e
	gen v35_hhchd_`z'ese=b11005_002m/1.645
	gen v35_hhchd_`z'dse=b11005_001m/1.645
	keep gidtr`z' v35*
	merge 1:1 gidtr`z' using pdx_ocl_data_tr`z'.dta, update nogen
	save pdx_ocl_data_tr`z'.dta, replace
	censusapi, url("https://api.census.gov/data/`ayr'/acs/acs5?get=group(B25003)&for=`f'&key=$censuskey") // homeownership
	*censusapi, url("https://api.census.gov/data/2020/dec/dhc?get=group(H10)&for=block:*&in=county:005,051,067&in=state:41") // 8mb
	gen gidtr`z'=substr(geo_id,10,.)
	gen v38_owner_`z'e=b25003_003e
	gen v38_owner_`z'd=b25003_001e
	gen v38_owner_`z'ese=b25003_003m/1.645
	gen v38_owner_`z'dse=b25003_001m/1.645
	keep gidtr`z' v38*
	merge 1:1 gidtr`z' using pdx_ocl_data_tr`z'.dta, update nogen
	save pdx_ocl_data_tr`z'.dta, replace
	censusapi, url("https://api.census.gov/data/`ayr'/acs/acs5?get=group(B25077)&for=`f'&key=$censuskey") // median owned homeval
	for var b*: cap replace X=. if X<-100000 // recode to missing
	gen gidtr`z'=substr(geo_id,10,.)
	gen v39_hval_`z'e=b25077_001e
	gen v39_hval_`z'se=b25077_001m/1.645
	keep gidtr`z' v39*
	merge 1:1 gidtr`z' using pdx_ocl_data_tr`z'.dta, update nogen
	save pdx_ocl_data_tr`z'.dta, replace
	censusapi, url("https://api.census.gov/data/`ayr'/acs/acs5?get=group(B25064)&for=`f'&key=$censuskey") // median gross rent
	for var b*: cap replace X=. if X<-100000 // recode to missing
	gen gidtr`z'=substr(geo_id,10,.)
	gen v3A_rent_`z'e=b25064_001e
	gen v3A_rent_`z'se=b25064_001m/1.645
	keep gidtr`z' v3A*
	merge 1:1 gidtr`z' using pdx_ocl_data_tr`z'.dta, update nogen
	save pdx_ocl_data_tr`z'.dta, replace
}
}
//
// table 4, part 2: engagement (tracts--2010,2020)
	// 2010
	foreach f in "tract:*&in=county:005,051,067&in=state:41" "place:59000&in=state:41" {
		censusapi, url("https://api.census.gov/data/2010/dec/responserate?get=GEO_ID,FSRR2010&for=`f'&key=$censuskey") // resprate.
		cap destring fsrr2010, replace force
		gen gidtr10=substr(geo_id,10,.)
		gen v43_srr_10=fsrr2010 // either (1) take the mean by HU weights of this, or (2) convert to a count.
		keep gidtr10 v43*
		merge 1:1 gidtr10 using pdx_ocl_data_tr10.dta, update nogen // srr dataset contains 1 unpopulated tract that is not in the acs
		save pdx_ocl_data_tr10.dta, replace 
		censusapi, url("https://api.census.gov/data/2010/dec/pl?get=GEO_ID,H001001&for=`f'&key=$censuskey")
		gen gidtr10=substr(geo_id,10,.)
		merge 1:1 gidtr10 using pdx_ocl_data_tr10.dta
		tab _merge
		drop _merge
		cap gen v43_srrhu_10=(v43_srr_10/100)*h001001 // now, it's the count of responding HUs (approx.)
		replace v43_srrhu_10=(v43_srr_10/100)*h001001
		keep gidtr10 v43_srrhu_10
		drop if v43_srrhu_10==. 
		merge 1:1 gidtr10 using pdx_ocl_data_tr10.dta, update nogen
		save pdx_ocl_data_tr10.dta, replace
		censusapi, url("https://api.census.gov/data/2011/acs/acs5?get=group(B07204)&for=`f'&key=$censuskey")  // movers
		destring * , replace
		gen gidtr10=substr(geo_id,10,.)
		gen v44_movein_10e=b07204_007e+b07204_016e // estimate
		gen v44_movein_10d=b07204_001e // denominoator
		gen v44_movein_10ese=sqrt((b07204_007m/1.645)^2+(b07204_016m/1.645)^2) // numerator SE
		gen v44_movein_10dse=b07204_001m/1.645 // denominators SE
		keep gidtr10 v44*
		merge 1:1 gidtr10 using pdx_ocl_data_tr10.dta, update nogen
		save pdx_ocl_data_tr10.dta, replace
	}
	// 2020
	foreach f in "tract:*&in=county:005,051,067&in=state:41" "place:59000&in=state:41" {
		censusapi, url("https://api.census.gov/data/2021/acs/acs5?get=group(B28011)&for=`f'&key=$censuskey")  // broadband
		gen gidtr20=substr(geo_id,10,.)
		gen v42_bbd_20e=b28011_004e
		gen v42_bbd_20d=b28011_001e
		gen v42_bbd_20ese=b28011_004m/1.645
		gen v42_bbd_20dse=b28011_001m/1.645
		keep gidtr20 v42*
		merge 1:1 gidtr20 using pdx_ocl_data_tr20.dta, update nogen
		save pdx_ocl_data_tr20.dta, replace
		censusapi, url("https://api.census.gov/data/2020/dec/responserate?get=GEO_ID,CRRALL,RESP_DATE&for=`f'&key=$censuskey") // resprate.
		gen gidtr20=substr(geo_id,10,.)
		gen v43_srr_20=crrall // either (1) take the mean by HU weights of this, or (2) convert to a count.
		keep gidtr20 v43*
		merge 1:1 gidtr20 using pdx_ocl_data_tr20.dta, update nogen // srr dataset contains 1 unpopulated tract that is not in the acs
		save pdx_ocl_data_tr20.dta, replace 
		censusapi, url("https://api.census.gov/data/2020/dec/pl?get=GEO_ID,H1_001N&for=`f'&key=$censuskey")
		gen gidtr20=substr(geo_id,10,.)
		merge 1:1 gidtr20 using pdx_ocl_data_tr20.dta
		tab _merge
		drop _merge
		cap gen v43_srrhu_20=(v43_srr_20/100)*h1_001n // now, it's the count of responding HUs (approx.)
		replace v43_srrhu_20=(v43_srr_20/100)*h1_001n
		keep gidtr20 v43_srrhu_20
		drop if v43_srrhu_20==. 
		merge 1:1 gidtr20 using pdx_ocl_data_tr20.dta, update nogen
		save pdx_ocl_data_tr20.dta, replace
		censusapi, url("https://api.census.gov/data/2021/acs/acs5?get=group(B07204)&for=`f'&key=$censuskey")  // movers
		destring * , replace
		gen gidtr20=substr(geo_id,10,.)
		gen v44_movein_20e=b07204_007e+b07204_016e // estimate
		gen v44_movein_20d=b07204_001e // denominoator
		gen v44_movein_20ese=sqrt((b07204_007m/1.645)^2+(b07204_016m/1.645)^2) // numerator SE
		gen v44_movein_20dse=b07204_001m/1.645 // denominators SE
		keep gidtr20 v44*
		merge 1:1 gidtr20 using pdx_ocl_data_tr20.dta, update nogen
		save pdx_ocl_data_tr20.dta, replace
	}
//
// table 5. education
forvalues y=2010(10)2020 {
	local z=`y'-2000
	local ayr=`y'+1
	if "`y'"=="2010" local ayr=`y'+2 // edu b15003 first appears in 2012 acs 
foreach f in "tract:*&in=county:005,051,067&in=state:41" "place:59000&in=state:41" {
	censusapi, url("https://api.census.gov/data/`ayr'/acs/acs5?get=group(B15003)&for=`f'&key=$censuskey")  // education
	gen gidtr`z'=substr(geo_id,10,.)
	gen v51_noged_`z'e=(b15003_002e+b15003_003e+b15003_004e+b15003_005e+b15003_006e+b15003_007e+b15003_008e+b15003_009e+b15003_010e+b15003_011e+b15003_012e+b15003_013e+b15003_014e+b15003_015e+b15003_016e)
	gen v51_noged_`z'd=b15003_001e
	gen v51_noged_`z'ese=sqrt((b15003_001m/1.645)^2+(b15003_002m/1.645)^2+(b15003_003m/1.645)^2+(b15003_004m/1.645)^2+(b15003_005m/1.645)^2+(b15003_006m/1.645)^2+(b15003_007m/1.645)^2+(b15003_008m/1.645)^2+(b15003_009m/1.645)^2+(b15003_010m/1.645)^2+(b15003_011m/1.645)^2+(b15003_012m/1.645)^2+(b15003_013m/1.645)^2+(b15003_014m/1.645)^2+(b15003_015m/1.645)^2+(b15003_016m/1.645)^2)
	gen v51_noged_`z'dse=b15003_001m/1.645
	gen v52_geba_`z'e=(b15003_022e+b15003_023e+b15003_024e+b15003_025e)
	gen v52_geba_`z'd=b15003_001e
	gen v52_geba_`z'ese=sqrt((b15003_022m/1.645)^2+(b15003_023m/1.645)^2+(b15003_024m/1.645)^2+(b15003_025m/1.645)^2)
	gen v52_geba_`z'dse=b15003_001m/1.645
	keep gidtr`z' v51* v52*
	merge 1:1 gidtr`z' using pdx_ocl_data_tr`z'.dta, update nogen
	save pdx_ocl_data_tr`z'.dta, replace
	censusapi, url("https://api.census.gov/data/`ayr'/acs/acs5?get=group(B14003)&for=`f'&key=$censuskey")  // public students 
	gen gidtr`z'=substr(geo_id,10,.)
	gen v53_pubschl_`z'e=b14003_003e+b14003_031e
	gen v53_pubschl_`z'd=b14003_003e+b14003_031e+b14003_012e+b14003_040e
	gen v53_pubschl_`z'ese=sqrt((b14003_003m/1.645)^2+(b14003_031m/1.645)^2)
	gen v53_pubschl_`z'dse=sqrt((b14003_003m/1.645)^2+(b14003_031m/1.645)^2+(b14003_012m/1.645)^2+(b14003_040m/1.645)^2)
	keep gidtr`z' v53*
	merge 1:1 gidtr`z' using pdx_ocl_data_tr`z'.dta, update nogen
	save pdx_ocl_data_tr`z'.dta, replace
}
}
//
// table 6: health, part 1: food (2010 tracts)
	use if state=="OR" using $food, clear  // food
	ren tractid gidtr10
	ren percent_food_insecure_2019 v61_food_20
	keep gidtr10 v61_food_20
	preserve
	cap merge 1:1 gidtr10 using pdx_ocl_data_tr10.dta, update nogen keep(2 3) // first merge to 2010 tracts, so cap
	save pdx_ocl_data_tr10.dta, replace 
	restore
	** downscale to bk10, add up to city.
	merge 1:m gidtr10 using pdx_ocl_tr10_to_bk10_factors.dta, nogen keep(2 3) // add block codes
	merge 1:1 gidbk10 using pdx_bk10_in_pdx.dta, keep(3) nogen // add pdx city flag, keep pdx blocks only
	merge 1:1 gidbk10 using pdx_ocl_data_bk10.dta, keep(1 3) keepus(v11_total_10) nogen // add bk10 pop
	collapse (mean) v61_food_20 [fw=v11_total_10], by(placefp)
	replace placefp="41"+placefp
	ren placefp gidtr10
	cap merge 1:1 gidtr10 using pdx_ocl_data_tr10.dta, update nogen 
	save pdx_ocl_data_tr10.dta, replace 
//
// table 6: health, part 2: life expect (from 2010 tracts)
	import delim using $e0, clear stringc(1) // e0
	ren tractid gidtr10
	ren see0 v64_e0_se_20
	ren e0 v64_e0_20
	keep gidtr10 v64_e0_20 // drop e0_se
	preserve
	merge 1:1 gidtr10 using pdx_ocl_data_tr10.dta, update nogen 
	save pdx_ocl_data_tr10.dta, replace
	restore
	** downscale to bk10, add up to city.
	merge 1:m gidtr10 using pdx_ocl_tr10_to_bk10_factors.dta, nogen keep(2 3) // add block codes
	merge 1:1 gidbk10 using pdx_bk10_in_pdx.dta, keep(3) nogen // add pdx city flag, keep pdx blocks only
	merge 1:1 gidbk10 using pdx_ocl_data_bk10.dta, keep(1 3) keepus(v11_total_10) nogen // add bk10 pop
	collapse (mean) v64_e0_20 [fw=v11_total_10], by(placefp)
	replace placefp="41"+placefp
	ren placefp gidtr10
	merge 1:1 gidtr10 using pdx_ocl_data_tr10.dta, update nogen 
	save pdx_ocl_data_tr10.dta, replace 
//
// table 6: health, part 3: SOVI (2020 tracts)
	import delim using $sovi, clear stringc(1/6) // metro svt
	ren geoid gidtr20
	ren social_vulnerability_index v63_sovi_20
	keep gidtr20 v63_sovi_20
	preserve
	merge 1:1 gidtr20 using pdx_ocl_data_tr20.dta, keep(2 3) nogen
	save pdx_ocl_data_tr20.dta, replace
	restore
	** downscale to bk20, add up to city.
	merge 1:m gidtr20 using pdx_ocl_tr20_to_bk20_factors.dta, nogen keep(2 3) // add block codes
	merge 1:1 gidbk20 using pdx_bk20_in_pdx.dta, keep(3) nogen // add pdx city flag, keep pdx blocks only
	merge 1:1 gidbk20 using pdx_ocl_data_bk20.dta, keep(1 3) keepus(v11_total_20) nogen // add bk10 pop
	collapse (mean) v63_sovi_20 [fw=v11_total_20], by(placefp)
	replace placefp="41"+placefp
	ren placefp gidtr20
	merge 1:1 gidtr20 using pdx_ocl_data_tr20.dta, update nogen 
	save pdx_ocl_data_tr20.dta, replace 
//
// table 6: health, part 4: disability (2020 tracts)
forvalues y=2010(10)2020 {
	local z=`y'-2000
	local ayr=`y'+1 
	if "`y'"=="2010" local ayr=`y'+2 // edu b18101 first appears in 2012 acs 
foreach f in "tract:*&in=county:005,051,067&in=state:41" "place:59000&in=state:41" {
	censusapi, url("https://api.census.gov/data/`ayr'/acs/acs5?get=group(B18101)&for=`f'&key=$censuskey")  // disability
	gen gidtr`z'=substr(geo_id,10,.)
	gen v62_disab_`z'e=(b18101_004e+b18101_007e+b18101_010e+b18101_013e+b18101_016e+b18101_019e+b18101_023e+b18101_026e+b18101_029e+b18101_032e+b18101_035e+b18101_038e)
	gen v62_disab_`z'd=(b18101_002e+b18101_021e)
	gen v62_disab_`z'ese=sqrt((b18101_004m/1.645)^2+(b18101_010m/1.645)^2+(b18101_013m/1.645)^2+(b18101_016m/1.645)^2+(b18101_019m/1.645)^2+(b18101_023m/1.645)^2+(b18101_026m/1.645)^2+(b18101_029m/1.645)^2+(b18101_032m/1.645)^2+(b18101_035m/1.645)^2+(b18101_038m/1.645)^2)
	gen v62_disab_`z'dse=sqrt((b18101_002m/1.645)^2+(b18101_021m/1.645)^2)
	keep gidtr`z' v62*
	merge 1:1 gidtr`z' using pdx_ocl_data_tr`z'.dta, update nogen
	save pdx_ocl_data_tr`z'.dta, replace
}
}
//
// table 7. income
forvalues y=2010(10)2020 {
	local z=`y'-2000
	local ayr=`y'+1 
foreach f in "tract:*&in=county:005,051,067&in=state:41" "place:59000&in=state:41" {
	censusapi, url("https://api.census.gov/data/`ayr'/acs/acs5?get=group(C17002)&for=`f'&key=$censuskey")  // poverty
	gen gidtr`z'=substr(geo_id,10,.)
	gen v71_pov_`z'e=(c17002_002e+c17002_003e)
	gen v71_pov_`z'd=c17002_001e
	gen v71_pov_`z'ese=sqrt((c17002_002m/1.645)^2+(c17002_003m/1.645)^2)
	gen v71_pov_`z'dse=c17002_001m/1.645
	keep gidtr`z' v71*
	merge 1:1 gidtr`z' using pdx_ocl_data_tr`z'.dta, update nogen
	save pdx_ocl_data_tr`z'.dta, replace
	censusapi, url("https://api.census.gov/data/`ayr'/acs/acs5?get=group(B19013)&for=`f'&key=$censuskey")  // median hhincome
	for var b*: cap replace X=. if X<-100000 // recode to missing
	gen gidtr`z'=substr(geo_id,10,.)
	gen v72_hhinc_`z'e=b19013_001e
	gen v72_hhinc_`z'se=b19013_001m/1.645
	keep gidtr`z' v72* 
	merge 1:1 gidtr`z' using pdx_ocl_data_tr`z'.dta, update nogen
	save pdx_ocl_data_tr`z'.dta, replace
	censusapi, url("https://api.census.gov/data/`ayr'/acs/acs5?get=group(B19001)&for=`f'&key=$censuskey")  // earn <75k
	gen gidtr`z'=substr(geo_id,10,.)
	gen v73_lt75k_`z'e=(b19001_002e+b19001_003e+b19001_004e+b19001_005e+b19001_006e+b19001_007e+b19001_008e+b19001_009e+b19001_010e+b19001_011e+b19001_012e)
	gen v73_lt75k_`z'd=b19001_001e
	gen v73_lt75k_`z'ese=sqrt((b19001_002m/1.645)^2+(b19001_003m/1.645)^2+(b19001_004m/1.645)^2+(b19001_005m/1.645)^2+(b19001_006m/1.645)^2+(b19001_007m/1.645)^2+(b19001_008m/1.645)^2+(b19001_009m/1.645)^2+(b19001_010m/1.645)^2+(b19001_011m/1.645)^2+(b19001_012m/1.645)^2)
	gen v73_lt75k_`z'dse=(b19001_001m/1.645)
	keep gidtr`z' v73* 
	merge 1:1 gidtr`z' using pdx_ocl_data_tr`z'.dta, update nogen
	save pdx_ocl_data_tr`z'.dta, replace
}
}
//
// table 8. language
foreach f in "tract:*&in=county:005,051,067&in=state:41" "place:59000&in=state:41" {
	// 2010
	censusapi, url("https://api.census.gov/data/2011/acs/acs5?get=group(B16001)&for=`f'&key=$censuskey")  // language-trt
	for var b16001_*m: replace X=(X/1.645)^2
	gen gidtr10=substr(geo_id,10,.)
	foreach t in "e" "m" {
		egen v82_lepspa_10`t'=rowtotal(b16001_005`t') // spa
		egen v82_lepfre_10`t'=rowtotal(b16001_008`t' b16001_011`t') // fr`t' cre
		egen v82_lepger_10`t'=rowtotal(b16001_020`t' b16001_023`t' b16001_026`t') // ger yid owg 
		egen v82_lepsla_10`t'=rowtotal(b16001_035`t' b16001_038`t' b16001_041`t' b16001_044`t') // rus pol ser ukr
		egen v82_lepoie_10`t'=rowtotal(b16001_014`t' b16001_017`t' b16001_047`t' b16001_050`t' b16001_053`t' b16001_056`t' b16001_059`t' b16001_062`t' b16001_065`t') // ita port gr`t' arm per guj hin urd oie
		egen v82_lepkor_10`t'=rowtotal(b16001_074`t') // kor
		egen v82_lepchn_10`t'=rowtotal(b16001_068`t') // chn
		egen v82_lepvie_10`t'=rowtotal(b16001_089`t') // vie
		egen v82_leptgl_10`t'=rowtotal(b16001_095`t') // tgl
		egen v82_lepoas_10`t'=rowtotal(b16001_077`t' b16001_080`t' b16001_083`t' b16001_086`t' b16001_092`t' b16001_098`t') // khm hmo tha lao oas oapi
		egen v82_lepara_10`t'=rowtotal(b16001_110`t') // ara
		egen v82_lepoth_10`t'=rowtotal(b16001_101`t' b16001_104`t' b16001_107`t' b16001_113`t' b16001_116`t' b16001_117`t') // nav aiain hung heb afri oth
	}
	egen v81_lep_10e=rowtotal(v82*_10e)
	egen v81_lep_10se=rowtotal(v82*_10m)
	replace v81_lep_10se=sqrt(v81_lep_10se)
	for var v82*10m: replace X=sqrt(X) 
	rename v82*10m v82*10se
	keep gidtr10 v8*
	merge 1:1 gidtr10 using pdx_ocl_data_tr10.dta, update nogen
	save pdx_ocl_data_tr10.dta, replace
	// 2020
	censusapi, url("https://api.census.gov/data/2021/acs/acs5?get=group(C16001)&for=`f'&key=$censuskey")  // language-trt
	gen gidtr20=substr(geo_id,10,.)
	gen v81_lep_20e=(c16001_005e+c16001_008e+c16001_011e+c16001_014e+c16001_017e+c16001_020e+c16001_023e+c16001_026e+c16001_029e+c16001_032e+c16001_035e+c16001_038e)
	gen v81_lep_20se=sqrt((c16001_005m/1.645)^2+(c16001_008m/1.645)^2+(c16001_011m/1.645)^2+(c16001_014m/1.645)^2+(c16001_017m/1.645)^2+(c16001_020m/1.645)^2+(c16001_023m/1.645)^2+(c16001_026m/1.645)^2+(c16001_029m/1.645)^2+(c16001_032m/1.645)^2+(c16001_035m/1.645)^2+(c16001_038m/1.645)^2)
	*gen v81_lep_20d=c16001_001e // pop age5+
	*gen v81_lep_20dse=c16001_005m/1.645
	#delimit ;
	gen v82_lepspa_20e=c16001_005e; gen v82_lepspa_20se=c16001_005m/1.645; 
	gen v82_lepfre_20e=c16001_008e; gen v82_lepfre_20se=c16001_008m/1.645; 
	gen v82_lepger_20e=c16001_011e; gen v82_lepger_20se=c16001_011m/1.645;
	gen v82_lepsla_20e=c16001_014e; gen v82_lepsla_20se=c16001_014m/1.645; 
	gen v82_lepoie_20e=c16001_017e; gen v82_lepoie_20se=c16001_017m/1.645; 
	gen v82_lepkor_20e=c16001_020e; gen v82_lepkor_20se=c16001_020m/1.645; 
	gen v82_lepchn_20e=c16001_023e; gen v82_lepchn_20se=c16001_023m/1.645; 
	gen v82_lepvie_20e=c16001_026e; gen v82_lepvie_20se=c16001_026m/1.645; 
	gen v82_leptgl_20e=c16001_029e; gen v82_leptgl_20se=c16001_029m/1.645; 
	gen v82_lepoas_20e=c16001_032e; gen v82_lepoas_20se=c16001_032m/1.645;
	gen v82_lepara_20e=c16001_035e; gen v82_lepara_20se=c16001_035m/1.645; 
	gen v82_lepoth_20e=c16001_038e; gen v82_lepoth_20se=c16001_038m/1.645;
	#delimit cr
	keep gidtr20 v8*
	merge 1:1 gidtr20 using pdx_ocl_data_tr20.dta, update nogen
	save pdx_ocl_data_tr20.dta, replace
}
// end tracts data compile 
}

/****************************
* downscale trt to blocks	*
****************************/

// downscale check
if $downscale==1 {

// 2020
	** 1. 2020 bk --> 2020 bk (begin to accumulate)
	use pdx_ocl_data_bk20.dta, clear
	save pdx_ocl_data_bk20_compiled.dta, replace // final compiled file, first time saved.
	**
	** 2. 2020 tr --> 2020 bk (accumulate)
	**		unmodified:    v63 (svt) v39 v3A v72 
	**		occhu weight:  v32 v33 v34 v35 v38 v42 (broadband) v43 
	**		hhpop weight:  v62 (disab) v71 v73
	** 		totpop weight: v44 v51 v52 v53 v8* 
	use pdx_ocl_data_tr20.dta, clear
	merge 1:m gidtr20 using pdx_ocl_tr20_to_bk20_factors.dta, keep(1 3) nogen // contains tr->bk alloc factors
	sort gidtr20 gidbk20
	replace gidbk20=gidtr20 if gidtr20=="4159000"
	for var *_shr_*: replace X=1 if gidtr20=="4159000"
	order gid* bk* v*, alpha
	for var v44* v51* v52* v53* v8*: replace X=X*bk20_shr_tr20_pop
	for var v43* v32* v33* v34* v35* v38* v42*: replace X=X*bk20_shr_tr20_hh
	for var v62* v71* v73*: replace X=X*bk20_shr_tr20_hhpop
	keep gidbk20 v*
	duplicates drop
	drop if gidbk20==""
	merge 1:1 gidbk20 using pdx_ocl_data_bk20_compiled.dta, nogen
	save pdx_ocl_data_bk20_compiled.dta, replace 
//
// 2010
	** 3. 2010 bk --> 2010 bk (begin to accumulate)
	use pdx_ocl_data_bk10.dta, clear
	order gidbk10 v*, alpha
	save pdx_ocl_data_bk10_compiled.dta, replace // final compiled file, first time saved
	**
	** 4. 2010 tr --> 2010 bk (accumulate)
	**		unmodified: v61 v64 (food e0) v39 v3A v72
	** 		occhu weight: v32 v33 v34 v35 v38 v43 
	**		hhpop weight: v62 v71 v73
	** 		totpop weight: v44 v51 v52 v53 v8* 
	use pdx_ocl_data_tr10.dta, clear
	merge 1:m gidtr10 using pdx_ocl_tr10_to_bk10_factors.dta, keep(1 3) nogen // tr->bk alloc factors
	sort gidtr10 gidbk10
	replace gidbk10=gidtr10 if gidtr10=="4159000"
	for var *_shr_*: replace X=1 if gidtr10=="4159000"
	order gid* bk* v*, alpha
	for var v44* v51* v52* v53* v8*: replace X=X*bk10_shr_tr10_pop
	for var v43* v32* v33* v34* v35* v38*: replace X=X*bk10_shr_tr10_hh
	for var v62* v71* v73*: replace X=X*bk10_shr_tr10_hhpop
	keep gidbk10 v*
	duplicates drop
	drop if gidbk10==""
	merge 1:1 gidbk10 using pdx_ocl_data_bk10_compiled.dta, nogen
	save pdx_ocl_data_bk10_compiled.dta, replace // accumulate

// end downscale 
}

/****************************
* summarize blocks to nhood	*
****************************/

// check
if $summarize==1 {

// summarize data by neighborhoods 
** 1. load intersected datasets, so 1:1 block merge. 
** 2. duplicate based on n of intersecting blocks (so duplicate when filtering by neighborhood)
//
// 2010bk->2010nh+city
	use "pdx_ocl_bk10_to_nhood11_sfbo.dta", clear // first, 2010 census to 2010 n'hoods+coalit
	merge m:1 gidbk10 using pdx_ocl_data_bk10_compiled.dta, assert(2 3) keepus(*_10*) nogen
	keep if gidbk10=="4159000" | nname!=""
	for var v1* v2*: replace X=X*prop_r10_sqft if gidbk10!="4159000" // adjust count data by proportions
	replace nname="CITY OF PORTLAND" if gidbk10=="4159000"
	replace nname="OLD TOWN-CHINATOWN" if nname=="OLD TOWN/CHINATOWN"
	gen count=strpos(nname,"/")>0 
	replace count=count+1
	split nname, p("/")
	expand count, gen(flag)
	sort gidbk10 nname flag
	replace nname=nname1 if flag==0
	replace nname=nname2 if flag==1
	drop count nname1 nname2 flag
	preserve
	for var v*se: replace X=X^2 // sum of squared errors
	collapse (sum) v1* v2* v31* v32* v33* v34* v35* v36* v37* v38* v4* v5* v62* v71* v73* v8*, by(nname) // was only v1* v2*
	for var v*se: replace X=sqrt(X)
	save tmp.dta
	restore
	preserve
	collapse (mean) v9* [iw=v11_total_10], by(nname) // median age 
	merge 1:1 nname using tmp.dta, nogen
	save tmp.dta, replace
	restore
	collapse (mean) v39* v3A* v72* [iw=v31_tothh_10], by(nname) // homeval/rent/hhinc
	merge 1:1 nname using tmp.dta, nogen
	rm tmp.dta
	* clean 2010nh ~ rename like 2020 names
	replace nname="BROOKLYN" if nname=="BROOKLYN ACTION CORPS" 
	replace nname="ARGAY TERRACE" if nname=="ARGAY"
	replace nname="OLD TOWN" if nname=="OLD TOWN-CHINATOWN"
	replace nname="SELLWOOD-MORELAND" if nname=="SELLWOOD-MORELAND IMPROVEMENT LEAGUE"
	replace nname="PORTLAND DOWNTOWN" if nname=="DOWNTOWN"
	replace nname="PEARL DISTRICT" if nname=="PEARL"
	drop if inlist(nname,"MAYWOOD PARK","NORTHWEST INDUSTRIAL") // NW INDUSTRIAL = MC UNCLAIMED #14
	drop if strpos(nname,"UNCLAIMED")>0
	keep if nname!=""
	save "pdx_ocl_nhood11.dta", replace // first save
//
// 2010bk->2010coalit
	use "pdx_ocl_bk10_to_nhood11_sfbo.dta", clear // multiple blocks with proportion in each nhood.
	merge m:1 gidbk10 using pdx_ocl_data_bk10_compiled.dta, assert(2 3) keep(3) keepus(*_10*) nogen // only keep blocks, not city
	keep if nname!=""
	for var v1* v2*: replace X=X*prop_r10_sqft // adjust count data by proportions
	gen count=strpos(coalit,"/")>0 
	replace count=count+1
	split coalit, p("/")
	expand count, gen(flag)
	sort gidbk10 coalit flag
	replace coalit=coalit1 if flag==0
	replace coalit=coalit2 if flag==1
	drop count coalit1 coalit2 flag
	preserve
	for var v*se: replace X=X^2 // sum of squared errors
	collapse (sum) v1* v2* v31* v32* v33* v34* v35* v36* v37* v38* v4* v5* v62* v71* v73* v8*, by(coalit) 
	for var v*se: replace X=sqrt(X)
	save tmp.dta
	restore
	preserve
	collapse (mean) v9* [iw=v11_total_10], by(coalit) // median age 
	merge 1:1 coalit using tmp.dta, nogen
	save tmp.dta, replace
	restore
	collapse (mean) v39* v3A* v72* [iw=v31_tothh_10], by(coalit) // homeval/rent/hhinc
	merge 1:1 coalit using tmp.dta, nogen
	rm tmp.dta
	* clean 2010coalit ~ rename like 2020 names
	drop if inlist(coalit,"none","NONE","unclaimed","UNCLAIMED","")
	replace coalit="EPCO" if coalit=="EPNO"
	replace coalit="SWCS" if coalit=="SWNI"
	ren coalit nname
	keep if nname!=""
	append using "pdx_ocl_nhood11.dta" 
	save "pdx_ocl_nhood11.dta", replace 
//
// 2010bk->2020nh+city
	use "pdx_ocl_bk10_to_nhood20_points.dta", clear // 2020 data in 2010 blocks
	merge m:1 gidbk10 using pdx_ocl_data_bk10_compiled.dta, assert(2 3) nogen keepus(v6* v11*) 
	keep if nname!="" | gidbk10=="4159000"
	replace nname="CITY OF PORTLAND" if gidbk10=="4159000"
	gen count=strpos(nname,"/")>0 
	replace count=count+1
	split nname, p("/")
	expand count, gen(flag)
	sort gidbk10 nname flag
	replace nname=nname1 if flag==0
	replace nname=nname2 if flag==1
	drop count nname1 nname2 flag
	collapse (mean) v6* [iw=v11_total_10], by(nname) // lifeexp and food
	save "pdx_ocl_nhood20.dta", replace // first save
// 2010bk->districts
	use "pdx_ocl_bk10_to_district", clear // 2010 blocks in 2020 districts
	merge 1:1 gidbk10 using pdx_ocl_data_bk10_compiled.dta, assert(2 3) keep(3) keepus(*_10* v6* v11*) nogen // add data in bk10 geos (srr, 2010 census)
	preserve
	for var v*se: replace X=X^2 // sum of squared errors
	collapse (sum) v1* v2* v31* v32* v33* v34* v35* v36* v37* v38* v4* v5* v62* v71* v73* v8*, by(nname) 
	for var v*se: replace X=sqrt(X)
	save tmp.dta
	restore
	preserve
	collapse (mean) v9* [iw=v11_total_10], by(nname) // median age 
	merge 1:1 nname using tmp.dta, nogen
	save tmp.dta, replace
	restore
	preserve
	collapse (mean) v39* v3A* v72* [iw=v31_tothh_10], by(nname) // homeval/rent/hhinc
	merge 1:1 nname using tmp.dta, nogen
	rm tmp.dta
	append using "pdx_ocl_nhood11.dta" 
	save "pdx_ocl_nhood11.dta", replace 
	restore
	collapse (mean) v6* [iw=v11_total_10], by(nname) // lifeexp, food
	append using "pdx_ocl_nhood20.dta" // append, because it's the first time these nnames (District X) are used. next time, merge.
	save "pdx_ocl_nhood20.dta", replace
// 
// 2010bk->2020coalit
	use "pdx_ocl_bk10_to_nhood20_points.dta", clear // 2020 data in 2010 blocks
	merge m:1 gidbk10 using pdx_ocl_data_bk10_compiled.dta, assert(2 3) keep(3) nogen keepus(v6* v11*) 
	keep if coalit!=""
	drop if inlist(coalit,"none","NONE","unclaimed","UNCLAIMED","")
	gen count=strpos(coalit,"/")>0 
	replace count=count+1
	split coalit, p("/")
	expand count, gen(flag)
	sort gidbk10 coalit flag
	replace coalit=coalit1 if flag==0
	replace coalit=coalit2 if flag==1
	drop count coalit1 coalit2 flag
	collapse (mean) v6* [iw=v11_total_10], by(coalit) // lifeexp and food
	replace coalit="EPCO" if coalit=="EPNO"
	replace coalit="SWCS" if coalit=="SWNI"
	ren coalit nname
	append using "pdx_ocl_nhood20.dta"
	save "pdx_ocl_nhood20.dta", replace
//
// 2020bk->2020nh+city
	use "pdx_ocl_bk20_to_nhood20_sfbo.dta", clear // third, data in 2020 blocks to 2020 nhoods
	merge m:1 gidbk20 using pdx_ocl_data_bk20_compiled.dta, assert(2 3) 
	keep if _merge==3 | gidbk20=="4159000"
	drop _merge
	replace nname="CITY OF PORTLAND" if gidbk20=="4159000"
	drop if nname==""
	for var v1* v2* v31* v32* v33* v34* v35* v36* v37* v38* v4* v5* v62* v65* v71* v73* v8*: replace X=X*prop_r20_sqft if gidbk20!="4159000" // adjust count data by proportions
	gen count=strpos(nname,"/")>0
	replace count=count+1
	split nname, p("/")
	expand count, gen(flag)
	sort gidbk20 nname flag
	replace nname=nname1 if flag==0
	replace nname=nname2 if flag==1
	drop count nname1 nname2 flag
	preserve
	for var v*se: replace X=X^2 // sum of squared errors
	collapse (sum) v1* v2* v31* v32* v33* v34* v35* v36* v37* v38* v4* v5* v62* v65* v71* v73* v8*, by(nname) 
	for var v*se: replace X=sqrt(X)
	save tmp.dta
	restore
	preserve
	collapse (mean) v39* v3A* v72* [iw=v31_tothh_20], by(nname) // homeval/rent/hhinc
	merge 1:1 nname using tmp.dta, nogen
	save tmp.dta, replace
	restore
	collapse (mean) v9* v63* [iw=v11_total_20], by(nname) // medage/svi
	merge 1:1 nname using tmp.dta, nogen
	rm tmp.dta
	merge 1:1 nname using "pdx_ocl_nhood20.dta", nogen
	save "pdx_ocl_nhood20.dta", replace // append
//
// 2020bk->2020coalit
	use "pdx_ocl_bk20_to_nhood20_sfbo.dta", clear // third, data in 2020 blocks to 2020 nhoods
	merge m:1 gidbk20 using pdx_ocl_data_bk20_compiled.dta, assert(2 3) keep(3) nogen // don't add city or superfluous blocks
	keep if coalit!=""
	drop if inlist(coalit,"none","NONE","unclaimed","UNCLAIMED","")
	for var v1* v2* v31* v32* v33* v34* v35* v36* v37* v38* v4* v5* v62* v65* v71* v73* v8*: replace X=X*prop_r20_sqft // adjust count data by proportions
	gen count=strpos(coalit,"/")>0
	replace count=count+1
	split coalit, p("/")
	expand count, gen(flag)
	sort gidbk20 coalit flag
	replace coalit=coalit1 if flag==0
	replace coalit=coalit2 if flag==1
	drop count coalit1 coalit2 flag
	preserve
	for var v*se: replace X=X^2 // sum of squared errors
	collapse (sum) v1* v2* v31* v32* v33* v34* v35* v36* v37* v38* v4* v5* v62* v65* v71* v73* v8*, by(coalit)
	for var v*se: replace X=sqrt(X) 
	save tmp.dta
	restore
	preserve
	collapse (mean) v39* v3A* v72* [iw=v31_tothh_20], by(coalit) // homeval/rent/hhinc
	merge 1:1 coalit using tmp.dta, nogen
	save tmp.dta, replace
	restore
	collapse (mean) v9* v63* [iw=v11_total_20], by(coalit) // medage/svi
	merge 1:1 coalit using tmp.dta, nogen
	rm tmp.dta
	ren coalit nname
	merge 1:1 nname using "pdx_ocl_nhood20.dta", nogen
	save "pdx_ocl_nhood20.dta", replace 
//
// 2020bk->districts
	use "pdx_ocl_bk20_to_district.dta", clear // blocks in a district
	merge 1:1 gidbk20 using pdx_ocl_data_bk20_compiled.dta, assert(2 3) keep(3) nogen // 2020 data in 2020 blocks
	preserve
	for var v*se: replace X=X^2 // sum of squared errors
	collapse (sum) v1* v2* v31* v32* v33* v34* v35* v36* v37* v38* v4* v5* v62* v65* v71* v73* v8*, by(nname)
	for var v*se: replace X=sqrt(X) 
	save tmp.dta
	restore
	preserve
	collapse (mean) v39* v3A* v72* [iw=v31_tothh_20], by(nname) // homeval/rent/hhinc
	merge 1:1 nname using tmp.dta, nogen
	save tmp.dta, replace
	restore
	collapse (mean) v9* v63* [iw=v11_total_20], by(nname) // medage/svi
	merge 1:1 nname using tmp.dta, nogen
	rm tmp.dta
	merge 1:1 nname using "pdx_ocl_nhood20.dta", nogen // "District X" entries in nname were added already, so merge this time.
	save "pdx_ocl_nhood20.dta", replace 

// end check summarize
}

/****************************
* clean data				*
****************************/

// check export
if $export==1 {

// now, combine nhood datasets and clean!!
// add together nh-level data 
	use "pdx_ocl_nhood20.dta", clear
	cap drop _merge
	drop if strpos(nname,"UNCLAIMED")>0
	replace nname="LLOYD DISTRICT" if nname=="LLOYD"
	merge 1:1 nname using "pdx_ocl_nhood11.dta", assert(3) nogen // add 2010 data for same areas
	merge 1:1 nname using "pdx_ocl_data_nharea.dta", assert(3) nogen // add land area
	save "pdx_ocl_profiles_ed2023_ndata.dta", replace // complete dataset, initial save.
	// rename coalitions using fullname
	foreach c in "CNN Central Northeast District" ///
				 "EPCOEast District" ///
				 "NWNWWest Northwest District" ///
				 "NPNSNorth District" ///
				 "NECNNortheast District" ///
				 "SEULSoutheast District" ///
				 "SWCSSouthwest District" {
		local coalit=trim(substr("`c'",1,4))
		local label=substr("`c'",5,.)
		replace nname=upper("`label'") if nname=="`coalit'"
	}
//
// generate proportions w/o SE
foreach y in "10" "20" { 
	gen v1O_pdensity_`y'=v11_total_`y'/v1N_sqmi_`y'
	gen v37_vacant_pct_`y'=v37_vacant_`y'/v37_tothu_`y' 
	drop v37_vacant_`y' v37_tothu_`y' 
	gen v36_pph_`y'=v36_hhpop_`y'/v31_tothh_`y'
	drop v36_hhpop_`y'
	gen v43_srrhu_pct_`y'=v43_srrhu_`y'/v31_tothh_`y'
	drop v43_srrhu_`y'
	cap drop v43_srr_`y'
}
	gen v41_turnout_pct_20=v41_turnout/(v1K_age1864_20+v1L_age65pl_20)
	drop v41_turnout v41_regvot
	gen v65_canopy_pct_20=v65_canopy_sqkm/(v1N_sqmi_20*2.5899984703)
	drop v65_canopy_sqkm 
//
// generate proportions w/SE
** se(shr)=1/denom * sqrt(se_numerator^2 -/+ (shr^2*se_denominator^2)) 
** per https://www2.census.gov/programs-surveys/acs/tech_docs/accuracy/2019_ACS_Accuracy_Document_Worked_Examples.pdf
foreach y in "10" "20" {
	foreach d in "v32_rentburd" "v33_srntburd" "v34_scrowd" "v35_hhchd" "v38_owner" "v44_movein" ///
		"v42_bbd" "v53_pubschl" "v51_noged" "v52_geba" "v62_disab" "v71_pov" "v73_lt75k" {
		if ("`d'_`y'"!="v42_bbd_10") { // this combination doesn't exist; all others do.
		gen `d'_pct_`y'=`d'_`y'e/`d'_`y'd
		gen `d'_pct_`y'se=(1/`d'_`y'd)*sqrt((`d'_`y'ese^2)-(((`d'_`y'e/`d'_`y'd)^2)*(`d'_`y'dse^2))) if ((`d'_`y'ese^2)>(((`d'_`y'e/`d'_`y'd)^2)*(`d'_`y'dse^2))) // if value under radical is positive
		replace `d'_pct_`y'se=(1/`d'_`y'd)*sqrt((`d'_`y'ese^2)+(((`d'_`y'e/`d'_`y'd)^2)*(`d'_`y'dse^2))) if ((`d'_`y'ese^2)<(((`d'_`y'e/`d'_`y'd)^2)*(`d'_`y'dse^2))) // if value under radical is negative
		gen `d'_rse_`y'=(`d'_pct_`y'se/`d'_pct_`y')
		replace `d'_rse_`y'=1 if `d'_pct_`y'==0 // missing if divide SE by estimate of zero; 100% RSE
		assert `d'_rse_`y'<.
		gen `d'_rel_`y'=(min(100,max(0,100*(1-`d'_rse_`y'))))
		drop `d'_`y'e `d'_`y'd `d'_`y'ese `d'_`y'dse `d'_pct_`y'se
		}
	}
	foreach d in "v39_hval" "v3A_rent" "v72_hhinc" {
		ren `d'_`y'e `d'_`y'
		gen `d'_rse_`y'=(`d'_`y'se/`d'_`y')
		replace `d'_rse_`y'=1 if `d'_`y'==0 // missing if divide SE by estimate of zero; 100% RSE
		assert `d'_rse_`y'<.
		gen `d'_rel_`y'=(min(100,max(0,100*(1-`d'_rse_`y'))))
		drop `d'_`y'se
	}
	cap drop v81_lep_`y'd
	cap drop v81_lep_`y'dse
	isvar v8*
	foreach l in "v81_lep" "v82_lepspa" "v82_lepfre" "v82_lepger" "v82_lepsla" "v82_lepoie" ///
		"v82_lepkor" "v82_lepchn" "v82_lepvie" "v82_leptgl" "v82_lepoas" "v82_lepara" "v82_lepoth" {
		ren `l'_`y'e `l'_`y'
		gen `l'_rse_`y'=(`l'_`y'se/`l'_`y')
		replace `l'_rse_`y'=1 if `l'_`y'==0
		assert `l'_rse_`y'<.
		gen `l'_rel_`y'=(min(100,max(0,100*(1-`l'_rse_`y'))))
		drop `l'_`y'se
	}
	egen lchk=rowtotal(v82_lep???_`y')
	assert inrange(lchk,v81_lep_`y'-3,v81_lep_`y'+3)
	drop lchk 
}
// 
// sort languages by number of speakers, per nhood (top 10).
** n.b. tied values will have the same ranks, and not always integers.
	preserve
	keep nname v81* v82*
	reshape long v82_lep@_20 v82_lep@_rel_20 v82_lep@_rse_20, i(nname v81_lep_20 v81_lep_rel_20 v81_lep_rse_20) string
	gsort nname -v82_lep_20
	by nname: gen leprank=_n
	reshape wide leprank@ v82_lep@_20 v82_lep@_rel_20 v82_lep@_rse_20, i(nname v81_lep_20 v81_lep_rel_20 v81_lep_rse_20) j(_j) string
	for num 1/12: gen v83_lepX_l_20="" // nth-ranked language
	for num 1/12: gen v83_lepX_n_20=. // number of speakers
	for num 1/12: gen v83_lepX_rse_20=. // rse
	foreach l in "spa Spanish" ///
				 "fre French (incl. Haitian)" ///
				 "ger German (incl. Dutch, Afrikaans)" ///
				 "sla Slavic (Russian, Ukrainian, Polish, others)" ///
				 "oie Other Ind./Eur. (Europe, Iran, India, others)" ///
				 "kor Korean" ///
				 "chn Chinese (incl. Mandarin, Cantonese, others)" ///
				 "vie Vietnamese" ///
				 "tgl Tagalog (incl. Filipino)" ///
				 "oas Other Asian and Pacific Islands" ///
				 "ara Arabic" ///
				 "oth Other (Africa, Eurasia, Oceania, Americas)" {
		local m=substr("`l'",4,.)
		local l=substr("`l'",1,3)
 		for num 1/12: replace v83_lepX_l_20="`m'" if leprank`l'==X & v83_lepX_l_20==""
		for num 1/12: replace v83_lepX_n_20=v82_lep`l'_20 if leprank`l'==X & v83_lepX_n_20==.
		for num 1/12: replace v83_lepX_rse_20=v82_lep`l'_rse_20 if leprank`l'==X & v83_lepX_rse_20==.		
	}
	save tmp.dta
	restore
	merge 1:1 nname using tmp.dta, keepus(v83*) assert(3) nogen // skip leprank* 
	rm tmp.dta
// 
// control totals ~ filter languages ~ cleanup languages
	egen lchk=rowtotal(v83_lep*_n_20)
	assert inrange(lchk,v81_lep_20-3,v81_lep_20+3)
	drop lchk v83_lep11_* v83_lep12_* // drop ranks 11/12, keep top 10 only.
//
// cleanup and check 
	for var *rel_20: replace X=round(X)
	for var *rse_20: replace X=round(X,.001) 
	ren v1N* v0* // rename landarea to avoid rounding with population counts
	for var v1* v2* v31* v81* v82_lep???_20 v83_*_n_20: replace X=round(X) // integer counts for age/race/hhds/lang
	ren v0* v1N* // rename landarea to put in correct sequence
	ren v9* v1M* // rename median age to put in correct sequence
	tostring v64_e0_20, replace format(%3.1f) force
	replace v64_e0_20="ND" if v64_e0_20==""|v64_e0_20=="0"|v64_e0_20=="."
	label var v11_total_20 "Total population "
	label var v12_age0004_20 "Population: Age 0-4"
	label var v13_age0509_20 "Population: Age 5-9"
	label var v14_age1014_20 "Population: Age 10-14"
	label var v15_age1519_20 "Population: Age 15-19"
	label var v16_age2024_20 "Population: Age 20-24"
	label var v17_age2529_20 "Population: Age 25-29"
	label var v18_age3034_20 "Population: Age 30-34"
	label var v19_age3539_20 "Population: Age 35-39"
	label var v1A_age4044_20 "Population: Age 40-44"
	label var v1B_age4549_20 "Population: Age 45-49"
	label var v1C_age5054_20 "Population: Age 50-54"
	label var v1D_age5559_20 "Population: Age 55-59"
	label var v1E_age6064_20 "Population: Age 60-64"
	label var v1F_age6569_20 "Population: Age 65-69"
	label var v1G_age7074_20 "Population: Age 70-74"
	label var v1H_age7579_20 "Population: Age 75-79"
	label var v1I_age80pl_20 "Population: Age 80+"
	label var v1J_agelt18_20 "Population: Age <18"
	label var v1K_age1864_20 "Population: Age 18-64"
	label var v1L_age65pl_20 "Population: Age 65+"
	label var v1M_medage_20 "Median age"
	label var v1N_sqmi_20 "Area (square miles)"
	label var v1O_pdensity_20 "Population density (persons per square mile)"
	label var v21_trt_20 "Race/Ethnicity: Total races tallied"
	label var v22_aian_20 "Race/Ethnicity: AIAN"
	label var v23_asian_20 "Race/Ethnicity: Asian"
	label var v24_black_20 "Race/Ethnicity: Black"
	label var v25_nhpi_20 "Race/Ethnicity: NHPI"
	label var v26_sor_20 "Race/Ethnicity: Other"
	label var v27_white_20 "Race/Ethnicity: White"
	label var v28_hispan_20 "Race/Ethnicity: Hispanic/Latino, any race"
	label var v29_wanh_20 "Race/Ethnicity: White alone, not Hispanic/Latino"
	label var v31_tothh_20 "Total Households"
	label var v32_rentburd_pct_20 "Rent Burdened Households % Total Rental Households"
	label var v32_rentburd_rse_20 "Rent Burdened Households % Total Rental Households (RelStdErr)"
	label var v32_rentburd_rel_20 "Rent Burdened Households % Total Rental Households (Reliability)"
	label var v33_srntburd_pct_20 "Severely Rent-Burdened Households % Total Rental Households"
	label var v33_srntburd_rse_20 "Severely Rent-Burdened Households % Total Rental Households (RelStdErr)"
	label var v33_srntburd_rel_20 "Severely Rent-Burdened Households % Total Rental Households (Reliability)"
	label var v34_scrowd_pct_20 "Severely Crowded Households % Total Households"
	label var v34_scrowd_rse_20 "Severely Crowded Households % Total Households (RelStdErr)"
	label var v34_scrowd_rel_20 "Severely Crowded Households % Total Households (Reliability)"
	label var v35_hhchd_pct_20 "Households With Children % Total Households"
	label var v35_hhchd_rse_20 "Households With Children % Total Households (RelStdErr)"
	label var v35_hhchd_rel_20 "Households With Children % Total Households (Reliability)"
	label var v36_pph_20 "Average Household Size"
	label var v37_vacant_pct_20 "Housing Vacancy Rate"
	label var v38_owner_pct_20 "Homeownership Rate"
	label var v38_owner_rse_20 "Homeownership Rate (RelStdErr)"
	label var v38_owner_rel_20 "Homeownership Rate (Reliability)"
	label var v39_hval_20 "Median Home Value Estimate"
	label var v39_hval_rse_20 "Median Home Value Estimate (RelStdErr)"
	label var v39_hval_rel_20 "Median Home Value Estimate (Reliability)"
	label var v3A_rent_20 "Median Contract Rent Estimate"
	label var v3A_rent_rse_20 "Median Contract Rent Estimate (RelStdErr)"
	label var v3A_rent_rel_20 "Median Contract Rent Estimate (Reliability)"
	label var v41_turnout_pct_20 "2020 General Election Turnout Rate"
	label var v42_bbd_pct_20 "Broadband Access % Total Households"
	label var v42_bbd_rse_20 "Broadband Access % Total Households (RelStdErr)"
	label var v42_bbd_rel_20 "Broadband Access % Total Households (Reliability)"
	label var v43_srrhu_pct_20 "Census Household Self-Response Rate"
	label var v44_movein_pct_20 "In-Movers In Past Year % Total Population Age 1+"
	label var v44_movein_rse_20 "In-Movers In Past Year % Total Population Age 1+ (RelStdErr)"
	label var v44_movein_rel_20 "In-Movers In Past Year % Total Population Age 1+ (Reliability)"
	label var v51_noged_pct_20 "Less Than Hs/Ged % Population Age 25+"
	label var v51_noged_rse_20 "Less Than Hs/Ged % Population Age 25+ (RelStdErr)"
	label var v51_noged_rel_20 "Less Than Hs/Ged % Population Age 25+ (Reliability)"
	label var v52_geba_pct_20 "Population With Ba Or Higher % Population Age 25+"
	label var v52_geba_rse_20 "Population With Ba Or Higher % Population Age 25+ (RelStdErr)"
	label var v52_geba_rel_20 "Population With Ba Or Higher % Population Age 25+ (Reliability)"
	label var v53_pubschl_pct_20 "Enrollment in Public School % Pop. Age 5-17 In School"
	label var v53_pubschl_rse_20 "Enrollment in Public School % Pop. Age 5-17 In School (RelStdErr)"
	label var v53_pubschl_rel_20 "Enrollment in Public School % Pop. Age 5-17 In School (Reliability)"
	label var v71_pov_pct_20 "Poverty Rate"
	label var v71_pov_rse_20 "Poverty Rate (RelStdErr)"
	label var v71_pov_rel_20 "Poverty Rate (Reliability)"
	label var v61_food_20 "Food Insecurity"
	label var v62_disab_pct_20 "Population w/Disability % Civilian Noninstitutionalized Pop."
	label var v62_disab_rse_20 "Population w/Disability % Civilian Noninstitutionalized Pop. (RelStdErr)"
	label var v62_disab_rel_20 "Population w/Disability % Civilian Noninstitutionalized Pop. (Reliability)"
	label var v63_sovi_20 "Metro Social Vulnerability Tools: Index"
	label var v64_e0_20 "Life Expectancy At Birth Estimate"
	label var v65_canopy_pct_20 "Tree Canopy % Total Area"
	label var v72_hhinc_20 "Median Household Income Estimate"
	label var v72_hhinc_rse_20 "Median Household Income Estimate (RelStdErr)"
	label var v72_hhinc_rel_20 "Median Household Income Estimate (Reliability)"
	label var v73_lt75k_pct_20 "Households Earning <$75K % Total Households"
	label var v73_lt75k_rse_20 "Households Earning <$75K % Total Households (RelStdErr)"
	label var v73_lt75k_rel_20 "Households Earning <$75K % Total Households (Reliability)"
	label var v81_lep_20 "Limited English Proficiency (LEP) Estimate"
	label var v81_lep_rse_20 "Limited English Proficiency (LEP) Estimate (RelStdErr)"
	label var v81_lep_rel_20 "Limited English Proficiency (LEP) Estimate (Reliability)"
	label var v82_lepspa_20 "LEP: Spanish Estimate"
	label var v82_lepspa_rse_20 "LEP: Spanish Estimate (RelStdErr)"
	label var v82_lepspa_rel_20 "LEP: Spanish Estimate (Reliability)"
	label var v82_lepfre_20 "LEP: French Estimate"
	label var v82_lepfre_rse_20 "LEP: French Estimate (RelStdErr)"
	label var v82_lepfre_rel_20 "LEP: French Estimate (Reliability)"
	label var v82_lepger_20 "LEP: German Estimate"
	label var v82_lepger_rse_20 "LEP: German Estimate (RelStdErr)"
	label var v82_lepger_rel_20 "LEP: German Estimate (Reliability)"
	label var v82_lepsla_20 "LEP: Slavic Estimate"
	label var v82_lepsla_rse_20 "LEP: Slavic Estimate (RelStdErr)"
	label var v82_lepsla_rel_20 "LEP: Slavic Estimate (Reliability)"
	label var v82_lepoie_20 "LEP: Other Indo-European Estimate"
	label var v82_lepoie_rse_20 "LEP: Other Indo-European Estimate (RelStdErr)"
	label var v82_lepoie_rel_20 "LEP: Other Indo-European Estimate (Reliability)"
	label var v82_lepkor_20 "LEP: Korean Estimate"
	label var v82_lepkor_rse_20 "LEP: Korean Estimate (RelStdErr)"
	label var v82_lepkor_rel_20 "LEP: Korean Estimate (Reliability)"
	label var v82_lepchn_20 "LEP: Chinese Estimate"
	label var v82_lepchn_rse_20 "LEP: Chinese Estimate (RelStdErr)"
	label var v82_lepchn_rel_20 "LEP: Chinese Estimate (Reliability)"
	label var v82_lepvie_20 "LEP: Vietnamese Estimate"
	label var v82_lepvie_rse_20 "LEP: Vietnamese Estimate (RelStdErr)"
	label var v82_lepvie_rel_20 "LEP: Vietnamese Estimate (Reliability)"
	label var v82_leptgl_20 "LEP: Tagalog Estimate"
	label var v82_leptgl_rse_20 "LEP: Tagalog Estimate (RelStdErr)"
	label var v82_leptgl_rel_20 "LEP: Tagalog Estimate (Reliability)"
	label var v82_lepoas_20 "LEP: Asia/Pacific Estimate"
	label var v82_lepoas_rse_20 "LEP: Asia/Pacific  Estimate (RelStdErr)"
	label var v82_lepoas_rel_20 "LEP: Other Asia/Pacific Estimate (Reliability)"
	label var v82_lepara_20 "LEP: Arabic Estimate"
	label var v82_lepara_rse_20 "LEP: Arabic Estimate (RelStdErr)"
	label var v82_lepara_rel_20 "LEP: Arabic Estimate (Reliability)"
	label var v82_lepoth_20 "LEP: All Other Estimate"
	label var v82_lepoth_rse_20 "LEP: All Other Estimate (RelStdErr)"
	label var v82_lepoth_rel_20 "LEP: All Other Estimate (Reliability)"
	label var v83_lep1_l_20 "LEP: Rank #1 (Language name)"
	label var v83_lep1_n_20 "LEP: Rank #1 (N LEP speakers)"
	label var v83_lep1_rse_20 "LEP: Rank #1 (RSE of N LEP speakers)"
	label var v83_lep2_l_20 "LEP: Rank #2 (Language name)"
	label var v83_lep2_n_20 "LEP: Rank #2 (N LEP speakers)"
	label var v83_lep2_rse_20 "LEP: Rank #2 (RSE of N LEP speakers)"
	label var v83_lep3_l_20 "LEP: Rank #3 (Language name)"
	label var v83_lep3_n_20 "LEP: Rank #3 (N LEP speakers)"
	label var v83_lep3_rse_20 "LEP: Rank #3 (RSE of N LEP speakers)"
	label var v83_lep4_l_20 "LEP: Rank #4 (Language name)"
	label var v83_lep4_n_20 "LEP: Rank #4 (N LEP speakers)"
	label var v83_lep4_rse_20 "LEP: Rank #4 (RSE of N LEP speakers)"
	label var v83_lep5_l_20 "LEP: Rank #5 (Language name)"
	label var v83_lep5_n_20 "LEP: Rank #5 (N LEP speakers)"
	label var v83_lep5_rse_20 "LEP: Rank #5 (RSE of N LEP speakers)"
	label var v83_lep6_l_20 "LEP: Rank #6 (Language name)"
	label var v83_lep6_n_20 "LEP: Rank #6 (N LEP speakers)"
	label var v83_lep6_rse_20 "LEP: Rank #6 (RSE of N LEP speakers)"
	label var v83_lep7_l_20 "LEP: Rank #7 (Language name)"
	label var v83_lep7_n_20 "LEP: Rank #7 (N LEP speakers)"
	label var v83_lep7_rse_20 "LEP: Rank #7 (RSE of N LEP speakers)"
	label var v83_lep8_l_20 "LEP: Rank #8 (Language name)"
	label var v83_lep8_n_20 "LEP: Rank #8 (N LEP speakers)"
	label var v83_lep8_rse_20 "LEP: Rank #8 (RSE of N LEP speakers)"
	label var v83_lep9_l_20 "LEP: Rank #9 (Language name)"
	label var v83_lep9_n_20 "LEP: Rank #9 (N LEP speakers)"
	label var v83_lep9_rse_20 "LEP: Rank #9 (RSE of N LEP speakers)"
	label var v83_lep10_l_20 "LEP: Rank #10 (Language name)"
	label var v83_lep10_n_20 "LEP: Rank #10 (N LEP speakers)"
	label var v83_lep10_rse_20 "LEP: Rank #10 (RSE of N LEP speakers)"
	label var nname "Area Name (Neighborhood, Coalition, or City)"
	** assign labels to 2010
	isvar v*20
	local n: word count `r(varlist)'
	tokenize `r(varlist)'
	forvalues x=1/`n' {
		local l: variable label ``x''
		local w=substr("``x''", 1, length("``x''")-2)
		cap label var `w'10 "`l'"
	}
	** generate admin level
	replace nname=proper(nname)
	replace nname=subinstr(nname,"'S","'s",.)
	replace nname=subinstr(nname,"Of","of",.)
	gen level=.
	replace level=1 if nname=="City of Portland"
	replace level=3 if strpos(nname,"District")>0 & strpos(nname,"Lloyd")==0 & strpos(nname,"Pearl")==0
	replace level=2 if inlist(substr(nname,10,1),"1","2","3","4")
	replace level=4 if level==.
	** order and sort
	order level nname v*, alpha
	sort level nname
	tab level, mis
	nois table nname if level==3, stat(sum v11_total_10 v11_total_20) nformat(%7.0fc)
//
// export
** block 1. denom = tot pop.
** block 2. denom = tot hhd.
** block 3. denom = tot hu.
** block 4. denom = trtally/totpop.
	gen expDate="2023-10-18"
	label var expDate "data production date"
	saveold "pdx_ocl_profiles_ed2023_ndata.dta", replace
	cap rm "pdx_ocl_profiles_ed2023_ndata.xlsx"
	export excel using "pdx_ocl_profiles_ed2023_ndata.xlsx", firstrow(variables) sheet(data, replace) 
	export delim using "pdx_ocl_profiles_ed2023_ndata.csv", replace
	preserve
	d, replace clear
	export excel using "pdx_ocl_profiles_ed2023_ndata.xlsx", firstrow(variables) sheet(codebook, modify) 
	export delim using "pdx_ocl_profiles_ed2023_ndata_dictionary.txt", delim(tab) replace
	restore

// end export
}

/*
// additional city-level languages for Portland city profile from PUMS
use if inlist(us2021c_puma,"01301","01302","01303","01305","01314") & us2021c_st=="41" using data/ipums_5acs21_lanp.dta, clear
renpfix us2021c_
destring *, replace ignore("BN")
svyset[pweight=pwgtp], vce(brr) brrweight(repwtp-repwtp80) fay(.5)mse	
gen lep=inlist(eng,2,3,4)
** replicate table b16001: spanish, french, haitian, italian, portuguese, german, yidd/dustch/w-germ, greek, russian, polish, serbo-croat, ukranian or other slavic, 
** 	armenian, persian (incl farsi, dari), gujarati, hindi, urdu, punjabi, bengali, nepali/marathi/other indic, other indo-euro, telugu, tamil, malayalm/kanna/dravidnan,
**	chinese (incl mand, canto), japanese, korean, hmong, viet, khmer, thai/lao/tai-kadai, other asian, tagalog (inc filipino), ilocano/samoan/hawaiian/other austronesian,
**	arabic, hebrew, amharic/somali/other afro-asiatic, yoruba/twi/igbo/other Western Africa, swahili/other central/eastern/southern afri, navajo, other aian, other/unspecified.
** portland priority table: 1spanish, 2vietnamese, 3chinese, 4russian, 5somali, 6ukrainian, 7romanian, 8nepali, 9chuukese, 10japanese, 11korean, 12tagalog, 13lao, 14arabic, 15mon-khmer
**  per: https://www.portlandoregon.gov/oehr/article/754396
recode lanp (1000/1175=16 "Other Indo-European") (1200=1 "Spanish") (1210=16) (1220=7 "Romanian") (1231/1242=16) (1250=4 "Russian") ///
	(1260=6 "Ukrainian") (1262/1450=16) (1500=8 "Nepali") (1525/1564=16) (1565/1582=19 "Other") (1675/1765=17 "Other Asian") (1900=15 "Khmer") (1960=2 "Vietnamese") ///
	(1970/2050=3 "Chinese") (2100/2430=17) (2475=13 "Lao") (2525/2535=17) (2560=10 "Japanese") (2575=11 "Korean") (2715/2850=17) (2910/2920=12 "Tagalog") ///
	(2950/3270=18 "Other Austronesian") (3350=9 "Chuukese") (3420/3600=18) (4500=14 "Arabic") (4545/4830=19) (4840=5 "Somali") (4880/9999=19), gen(langrc)
eststo clear
estpost svy,subpop(lep): tab langrc, count format(%8.0fc) se
esttab . using "pdx_ocl_data_city_lang.txt", noobs not nonotes nonumbers mlab("LEP Count") nostar wide se replace

*/
